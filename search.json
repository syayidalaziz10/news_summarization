[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Repository Tugas Pencarian dan Penambangan Web",
    "section": "",
    "text": "Tentang\nBerikut merupakan repository yang saya buat berisikan tugas pada mata kuliah Pencarian dan Penambangan Web, dalam repository ini berisikan topic modeling pada tugas akhir Universitas Trunojoyo Madura dan ringkasan berita pada yang datanya diambil pada website CNN Indonesia, tidak hanya itu terdapat juga beberapa langkah-langkah mulai dari pengambilan data (crawling) dan tahapan utama hingga selesai dari kedua pekerjaan ini yaitu topic modeling dan ringkasan dokumen."
  },
  {
    "objectID": "crawl_pta_trunojoyo.html",
    "href": "crawl_pta_trunojoyo.html",
    "title": "1  Crawl PTA Trunojoyo",
    "section": "",
    "text": "!pip install requests\n!pip install beautifulsoup4\nimport requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\n\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.2.0)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.4)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.7.22)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\nRequirement already satisfied: soupsieve&gt;1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.4.1)\n\n\n\n2 Crawling Data\n\ndef ptaa():\n    data = {\"penulis\": [], \"judul\": [], \"pembimbing_pertama\": [], \"pembimbing_kedua\": [], \"abstrak\": []}\n\n    for i in range(1, 4):\n        url = \"https://pta.trunojoyo.ac.id/c_search/byprod/10/{}\".format(i)\n        r = requests.get(url)\n        request = r.content\n        soup = BeautifulSoup(request, \"html.parser\")\n        jurnals = soup.select('li[data-cat=\"#luxury\"]')\n\n        for jurnal in jurnals:\n            response = requests.get(jurnal.select_one('a.gray.button')['href'])\n            soup1 = BeautifulSoup(response.content, \"html.parser\")\n\n            isi = soup1.select_one('div#content_journal')\n\n            judul = isi.select_one('a.title').text\n\n            penulis = isi.select_one('span:contains(\"Penulis\")').text.split(' : ')[1]\n            # penulis = penulis_span.find_next('span').text.split(' : ')\n\n            pembimbing_pertama = isi.select_one('span:contains(\"Dosen Pembimbing I\")').text.split(' : ')[1]\n            # pembimbing_pertama = pembimbing_pertama_span.find_next('span')\n\n            pembimbing_kedua = isi.select_one('span:contains(\"Dosen Pembimbing II\")').text.split(' :')[1]\n            # pembimbing_kedua = pembimbing_kedua_span.find_next('span')\n\n            abstrak = isi.select_one('p[align=\"justify\"]').text\n            if abstrak == '':\n              abstrak = ' '.join(isi.find('p').findNext('p').stripped_strings).capitalize()\n\n            data[\"penulis\"].append(penulis)\n            data[\"judul\"].append(judul)\n            data[\"pembimbing_pertama\"].append(pembimbing_pertama)\n            data[\"pembimbing_kedua\"].append(pembimbing_kedua)\n            data[\"abstrak\"].append(abstrak)\n\n    df = pd.DataFrame(data)\n    df.to_csv(\"pta.csv\", index=False)\n\n    return df\n\n\nptaa()\n\n\n  \n    \n\n\n\n\n\n\npenulis\njudul\npembimbing_pertama\npembimbing_kedua\nabstrak\n\n\n\n\n0\nA.Ubaidillah S.Kom\nPERANCANGAN DAN IMPLEMENTASI SISTEM DATABASE \\...\nBudi Setyono M.T\nHermawan S.T\nSistem informasi akademik (SIAKAD) merupaka...\n\n\n1\nM. Basith Ardianto,\nAPLIKASI KONTROL DAN MONITORING JARINGAN KOMPU...\nDrs. Budi Soesilo, MT\nKoko Joni, ST\nBerjalannya koneksi jaringan komputer dengan l...\n\n\n2\nAkhmad Suyandi, S.Kom\nRANCANG BANGUN APLIKASI PROXY SERVER UNTUK\\r\\n...\nDrs. Budi Soesilo, M.T\nHermawan, ST, MT\nWeb server adalah sebuah perangkat lunak serve...\n\n\n3\nHeri Supriyanto\nSISTEM PENDUKUNG KEPUTUSAN OPTIMASI PENJADWALA...\nMulaab, S.Si., M.Kom\nFirli Irhamni, ST., M.Kom\nPenjadwalan kuliah di Perguruan Tinggi me...\n\n\n4\nSeptian Rahman Hakim\nSISTEM AUGMENTED REALITY ANIMASI BENDA BERGERA...\nArik Kurniawati, S.Kom., M.T.\nHaryanto, S.T., M.T.\nSeiring perkembangan teknologi yang ada diduni...\n\n\n5\nAdi Chandra Laksono\nGerak Pekerja Pada Game Real Time Strategy Men...\nKurniawan Eka P, S.Kom., Msc\nArik Kurniawati, S.Kom., M.T.\nGerak pekerja ada pada game yang memiliki genr...\n\n\n6\nNURRACHMAT\nRANCANG BANGUN GAME PERAWATAN SAPI KARAPAN MEN...\nArik Kurniawati, S.Kom., M.T.\nKurniawan Eka Permana, S.Kom., MSc.\nPerkembangan game yang semakin pesat, memberik...\n\n\n7\nMuhammad Choirur Rozi\nEKSTRAKSI FITUR BERBASIS TWO DIMENSIONAL LINEA...\nDr. Arif Muntasa, S.Si.,M.T\nFitri Damayanti, S.Kom.,M.kom\nSistem pengenalan wajah adalah suatu sistem un...\n\n\n8\nM Khoiril Anwar\nIMPLEMENTASI ALGORITMA PRIM DAN DEPTH FIRST ...\nCucun Very Angkoso, S.T., M.T.\nArik Kurniawati S. Kom., M.T.\nTeknologi mobile game beroperating system open...\n\n\n9\nMALIKUL HAMZAH\nPerancangan Sistem Informasi Badan Kepegawaian...\nMoch. Kautsar Sophan, S.Kom., M.MT.\nYeni Kustiyaningsih, S.Kom., M.Kom.\nKantor Badan Kepegawaian kota Bangkalan adalah...\n\n\n10\nNorman\nPEMANFAATAN TOGAF ADM UNTUK PERANCANGAN SISTEM...\nM. Kautsar Sophan, S.Kom., M. MT.\nYeni Kustiyahningsih S.Kom., M.Kom.\nPenyusunan Sistem Informasi Dinas Perindustria...\n\n\n11\nRobiatul Adawiyah, S.Kom\nAPLIKASI METODE FUZZY ANALYTIC NETWORK PROCESS...\nDiana Rahmawati, S.T, M.T\nBudi Dwi Satoto, S.T, M.Kom\nPerusahaan pemerintah maupun swasta mempunyai ...\n\n\n12\nDesy Mariana S. Kom\nSISTEM PENDUKUNG KEPUTUSAN REKOMENDASI MENU DI...\nHaryanto ST, MT\nFirli Irhamni ST, M. Kom\nPelayanan makanan bagi pasien rawat inap di Ru...\n\n\n13\nLia Fransiska\nRANCANG BANGUN APLIKASI PEMILIHAN TEKNIK REKAY...\nFirli Irhamni S.T, M.Kom\nBudi Dwi Satoto S.T, M.Kom\nPenyusunan Sistem Pendukung Keputusan pemiliha...\n\n\n14\nErwina Safitri\nDETEKSI COREPOINT SIDIK JARI MENGGUNAKAN METOD...\nDr. Indah Agustien, S.Kom., M.Kom\nFitri Damayanti, S.Kom., M.Kom\nSidik jari adalah salah satu karakteristik fis..."
  },
  {
    "objectID": "topic_modeling_pta.html",
    "href": "topic_modeling_pta.html",
    "title": "2  Topic Modeling PTA",
    "section": "",
    "text": "3 Instalisasi\n!pip install nltk\n!pip install Sastrawi\n!pip install gensim\n\nRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\nRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\nRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\nRequirement already satisfied: regex&gt;=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\nRequirement already satisfied: Sastrawi in /usr/local/lib/python3.10/dist-packages (1.0.1)\nRequirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\nRequirement already satisfied: numpy&gt;=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.23.5)\nRequirement already satisfied: scipy&gt;=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.3)\nRequirement already satisfied: smart-open&gt;=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\nimport pandas as pd\nimport nltk\nimport gensim\nimport re\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom nltk.corpus import stopwords\nfrom gensim import corpora\nfrom gensim.models import LdaModel\nfrom gensim.models.coherencemodel import CoherenceModel\nfrom Sastrawi.Stemmer.StemmerFactory import StemmerFactory\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, silhouette_score\nnltk.download(\"punkt\")\nnltk.download(\"stopwords\")\n\n[nltk_data] Downloading package punkt to /root/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n\n\nTrue\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\ncsv_path = '/content/drive/My Drive/Study Of Informatika/Pencarian dan Penambangan Web/Tugas 1/data/pta-teknik-informatika-with-label.csv'\ndf = pd.read_csv(csv_path)\ndf\n\nDrive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n\n\n\n  \n    \n\n\n\n\n\n\npenulis\njudul\npembimbing_pertama\npembimbing_kedua\nabstrak\nlabel-topic\n\n\n\n\n0\nA.Ubaidillah S.Kom\nPERANCANGAN DAN IMPLEMENTASI SISTEM DATABASE T...\nBudi Setyono M.T\nHermawan S.T\nSistem informasi akademik (SIAKAD) merupaka...\nrpl\n\n\n1\nM. Basith Ardianto,\nAPLIKASI KONTROL DAN MONITORING JARINGAN KOMPU...\nDrs. Budi Soesilo, MT\nKoko Joni, ST\nBerjalannya koneksi jaringan komputer dengan l...\nrpl\n\n\n2\nAkhmad Suyandi, S.Kom\nRANCANG BANGUN APLIKASI PROXY SERVER UNTUK\\nEN...\nDrs. Budi Soesilo, M.T\nHermawan, ST, MT\nWeb server adalah sebuah perangkat lunak serve...\nrpl\n\n\n3\nHeri Supriyanto\nSISTEM PENDUKUNG KEPUTUSAN OPTIMASI PENJADWALA...\nMulaab, S.Si., M.Kom\nFirli Irhamni, ST., M.Kom\nPenjadwalan kuliah di Perguruan Tinggi me...\nkomputasi\n\n\n4\nSeptian Rahman Hakim\nSISTEM AUGMENTED REALITY ANIMASI BENDA BERGERA...\nArik Kurniawati, S.Kom., M.T.\nHaryanto, S.T., M.T.\nSeiring perkembangan teknologi yang ada diduni...\nkomputasi\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n826\nRachmad Agung Pambudi\nPENERAPAN ALGORITMA LONG-SHORT TERM MEMORY UNT...\nEka Mala Sari Rochman, S.Kom., M.Kom\nSri Herawati, S.Kom., M.Kom\nInvestasi saham selama ini memiliki resiko ker...\nkomputasi\n\n\n827\nNadila Hidayanti\nSISTEM PENCARIAN TEKS AL-QURAN TERJEMAHAN BERB...\nAchmad Jauhari, S.T., M.Kom\nIka Oktavia Suzanti, S.Kom., M.Cs\nInformation Retrieval (IR) merupakan pengambil...\nkomputasi\n\n\n828\nAfni Sakinah\nKLASIFIKASI KOMPLEKSITAS VISUAL CITRA SAMPAH M...\nDr. Indah Agustien Siradjuddin, S.Kom., M.Kom.\nMoch. Kautsar Sophan, S.Kom., M.MT.\nKlasifikasi citra merupakan proses pengelompok...\nkomputasi\n\n\n829\nFriska Fatmawatiningrum\nIDENTIFIKASI BINER ATRIBUT PEJALAN KAKI MENGGU...\nDr. Indah Agustien Siradjuddin, S.Kom., M.Kom.\nProf. Dr. Arief Muntasa, S.Si., M.MT.\nIdentifikasi atribut pejalan kaki merupakan sa...\nkomputasi\n\n\n830\nDian Wibowo\nDETEKSI OBJEK MANUSIA BERBASIS ONE STAGE DETEC...\nDr. Indah Agustien Siradjuddin, S.Kom., M.Kom.\nMoch. Kautsar Sophan, S.Kom., M.MT.\nTopik deteksi objek telah menarik perhatian ya...\nkomputasi\n\n\n\n\n\n831 rows × 6 columns\ncount_komputasi = (df['label-topic'] == 'komputasi').sum()\ncount_rpl = (df['label-topic'] == 'rpl').sum()\n\nprint('komputasi = ', count_komputasi, 'rpl = ', count_rpl)\n\nkomputasi =  548 rpl =  283\nText preprocessing merupakan tahapan dalam Natural Language Processing (NLP) yang bertujuan untuk membersihkan dan menyiapkan teks mentah menjadi data siap digunakan pada proses yang lebih lanjut. Text preprocessing ini menjadi sangat krusial karena membantu mengatasi berbagai masalah seperti data berantakan, tanda baca yang berlebihan, serta variasi dalam bentuk kata\ndf=df.astype(str)\ndf[\"abstrak\"] = df[\"abstrak\"].apply(lambda x: x.lower())\n\nabstrak_column = df[\"abstrak\"]\nabstrak_column\n\n0      sistem  informasi  akademik  (siakad) merupaka...\n1      berjalannya koneksi jaringan komputer dengan l...\n2      web server adalah sebuah perangkat lunak serve...\n3      penjadwalan  kuliah  di  perguruan  tinggi  me...\n4      seiring perkembangan teknologi yang ada diduni...\n                             ...                        \n826    investasi saham selama ini memiliki resiko ker...\n827    information retrieval (ir) merupakan pengambil...\n828    klasifikasi citra merupakan proses pengelompok...\n829    identifikasi atribut pejalan kaki merupakan sa...\n830    topik deteksi objek telah menarik perhatian ya...\nName: abstrak, Length: 831, dtype: object\nFeature extraction ini digunakan untuk mengubah keseluruhan teks dalam dokumen menjadi angka numerik dengan menggunakan algoritma TF-IDF dan LDA Topic\ncsv_preprocessing = '/content/drive/My Drive/Study Of Informatika/Pencarian dan Penambangan Web/Tugas 1/data/processing-data/preprocessing.csv'\ndata = pd.read_csv(csv_preprocessing)\ndata\n\n\n  \n    \n\n\n\n\n\n\npenulis\njudul\npembimbing_pertama\npembimbing_kedua\nabstrak\nlabel-topic\nstopword-abstrak\nsteeming-abstrak\n\n\n\n\n0\nA.Ubaidillah S.Kom\nPERANCANGAN DAN IMPLEMENTASI SISTEM DATABASE T...\nBudi Setyono M.T\nHermawan S.T\nsistem informasi akademik (siakad) merupaka...\nrpl\nsistem informasi akademik siakad sistem inform...\nsistem informasi akademik siakad sistem inform...\n\n\n1\nM. Basith Ardianto,\nAPLIKASI KONTROL DAN MONITORING JARINGAN KOMPU...\nDrs. Budi Soesilo, MT\nKoko Joni, ST\nberjalannya koneksi jaringan komputer dengan l...\nrpl\nberjalannya koneksi jaringan komputer lancar g...\njalan koneksi jaring komputer lancar ganggu ha...\n\n\n2\nAkhmad Suyandi, S.Kom\nRANCANG BANGUN APLIKASI PROXY SERVER UNTUK\\nEN...\nDrs. Budi Soesilo, M.T\nHermawan, ST, MT\nweb server adalah sebuah perangkat lunak serve...\nrpl\nweb server perangkat lunak server berfungsi me...\nweb server perangkat lunak server fungsi terim...\n\n\n3\nHeri Supriyanto\nSISTEM PENDUKUNG KEPUTUSAN OPTIMASI PENJADWALA...\nMulaab, S.Si., M.Kom\nFirli Irhamni, ST., M.Kom\npenjadwalan kuliah di perguruan tinggi me...\nkomputasi\npenjadwalan kuliah perguruan kompleks permasal...\njadwal kuliah guru kompleks masalah variabel t...\n\n\n4\nSeptian Rahman Hakim\nSISTEM AUGMENTED REALITY ANIMASI BENDA BERGERA...\nArik Kurniawati, S.Kom., M.T.\nHaryanto, S.T., M.T.\nseiring perkembangan teknologi yang ada diduni...\nkomputasi\nperkembangan teknologi didunia muncul teknolog...\nkembang teknologi dunia muncul teknologi augme...\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n826\nRachmad Agung Pambudi\nPENERAPAN ALGORITMA LONG-SHORT TERM MEMORY UNT...\nEka Mala Sari Rochman, S.Kom., M.Kom\nSri Herawati, S.Kom., M.Kom\ninvestasi saham selama ini memiliki resiko ker...\nkomputasi\ninvestasi saham memiliki resiko kerugian perge...\ninvestasi saham milik resiko rugi gera harga s...\n\n\n827\nNadila Hidayanti\nSISTEM PENCARIAN TEKS AL-QURAN TERJEMAHAN BERB...\nAchmad Jauhari, S.T., M.Kom\nIka Oktavia Suzanti, S.Kom., M.Cs\ninformation retrieval (ir) merupakan pengambil...\nkomputasi\ninformation retrieval ir pengambilan informasi...\ninformation retrieval ir ambil informasi simpa...\n\n\n828\nAfni Sakinah\nKLASIFIKASI KOMPLEKSITAS VISUAL CITRA SAMPAH M...\nDr. Indah Agustien Siradjuddin, S.Kom., M.Kom.\nMoch. Kautsar Sophan, S.Kom., M.MT.\nklasifikasi citra merupakan proses pengelompok...\nkomputasi\nklasifikasi citra proses pengelompokan piksel ...\nklasifikasi citra proses kelompok piksel citra...\n\n\n829\nFriska Fatmawatiningrum\nIDENTIFIKASI BINER ATRIBUT PEJALAN KAKI MENGGU...\nDr. Indah Agustien Siradjuddin, S.Kom., M.Kom.\nProf. Dr. Arief Muntasa, S.Si., M.MT.\nidentifikasi atribut pejalan kaki merupakan sa...\nkomputasi\nidentifikasi atribut pejalan kaki salah peneli...\nidentifikasi atribut pejal kaki salah teliti k...\n\n\n830\nDian Wibowo\nDETEKSI OBJEK MANUSIA BERBASIS ONE STAGE DETEC...\nDr. Indah Agustien Siradjuddin, S.Kom., M.Kom.\nMoch. Kautsar Sophan, S.Kom., M.MT.\ntopik deteksi objek telah menarik perhatian ya...\nkomputasi\ntopik deteksi objek menarik perhatian perkemba...\ntopik deteksi objek tarik perhati kembang tekn...\n\n\n\n\n\n831 rows × 8 columns\nget_steeming_abstrak = df[\"steeming-abstrak\"]\nget_stopword_abstrak = df[\"stopword-abstrak\"]\nUntuk melakukan clustering akan menggunakan hasil fitur yang didapatkan pada ekstraksi kalimat di tahapan sebelumnya dengan menggunakan TF-IDF dan LDA Topic. Kedua algoritma tersebut memiliki cara kerja yang berbeda maka dengan melakukukan perbandingan nilai skor yang dihasilkan pada saat clustering dokumen maka nanti dapat diambil kesimpulan dari hasil ektraksi fitur yang terbaik ketika menggunakan kedua algoritma tersebut.\ndef kmeans_clustering(data):\n    scaler = StandardScaler()\n    scaled_data = scaler.fit_transform(data)\n    num_clusters = 3\n    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n    clusters = kmeans.fit_predict(scaled_data)\n    return clusters\nSama halnya pada clustering, proses klasifikasi kali ini akan membandingkan antara kedua algoritma ektraksi fitur yaitu TF-IDF dan LDA Topic sehingga nanti akan dihasilkan perbandingan antara akurasi terbaik ketika menggunakan LDA atau TF-IDF"
  },
  {
    "objectID": "topic_modeling_pta.html#tokenisasi",
    "href": "topic_modeling_pta.html#tokenisasi",
    "title": "2  Topic Modeling PTA",
    "section": "5.1 Tokenisasi",
    "text": "5.1 Tokenisasi\nTokenizing adalah proses yang mengubah teks berkelanjutan menjadi unit-unit yang lebih kecil dan disebut dengan token. Token ini biasanya adalah kata, frasa, atau tanda baca yang memisahkan kata-kata dalam teks, dengan ini akan memudahkan untuk melakukan analisis terhadap teks dan akan membantu menyaring kata-kata yang tidak diinginkan pada pemrosesan teks lebih lanjut\n\ndef process_tokenize(text):\n    text = text.split()\n    return text\n\ntokenize_abstrak = abstrak_column.apply(process_tokenize)\ntokenize_abstrak\n\n# token = pd.DataFrame(df, columns = tokenize_abstrak)\n\n0      [sistem, informasi, akademik, (siakad), merupa...\n1      [berjalannya, koneksi, jaringan, komputer, den...\n2      [web, server, adalah, sebuah, perangkat, lunak...\n3      [penjadwalan, kuliah, di, perguruan, tinggi, m...\n4      [seiring, perkembangan, teknologi, yang, ada, ...\n                             ...                        \n826    [investasi, saham, selama, ini, memiliki, resi...\n827    [information, retrieval, (ir), merupakan, peng...\n828    [klasifikasi, citra, merupakan, proses, pengel...\n829    [identifikasi, atribut, pejalan, kaki, merupak...\n830    [topik, deteksi, objek, telah, menarik, perhat...\nName: abstrak, Length: 831, dtype: object"
  },
  {
    "objectID": "topic_modeling_pta.html#process-punctuation",
    "href": "topic_modeling_pta.html#process-punctuation",
    "title": "2  Topic Modeling PTA",
    "section": "5.2 Process Punctuation",
    "text": "5.2 Process Punctuation\nProses punctuation ini digunakan untuk mengahapus karakter yang tidak digunakan pada teks, seperti tanda baca dan angka. Beberapa karakter ini harus dihilangkan karena karakter tersebut tidak akan mempengaruhi hasil pada saat melakukan klasifikasi topic\n\ndef process_punctuation(tokens):\n    cleaned_tokens = [re.sub(r'[.,()&=%:-]', '', token) for token in tokens]\n    cleaned_tokens = [re.sub(r'\\d+', '', token) for token in cleaned_tokens]\n\n    return cleaned_tokens\n\npunctuation_abstrak = tokenize_abstrak.apply(process_punctuation)\n\n# data = pd.DataFrame(df, columns=['punctuation_abstrak'])\n# data\npunctuation_abstrak\n\n0      [sistem, informasi, akademik, siakad, merupaka...\n1      [berjalannya, koneksi, jaringan, komputer, den...\n2      [web, server, adalah, sebuah, perangkat, lunak...\n3      [penjadwalan, kuliah, di, perguruan, tinggi, m...\n4      [seiring, perkembangan, teknologi, yang, ada, ...\n                             ...                        \n826    [investasi, saham, selama, ini, memiliki, resi...\n827    [information, retrieval, ir, merupakan, pengam...\n828    [klasifikasi, citra, merupakan, proses, pengel...\n829    [identifikasi, atribut, pejalan, kaki, merupak...\n830    [topik, deteksi, objek, telah, menarik, perhat...\nName: abstrak, Length: 831, dtype: object"
  },
  {
    "objectID": "topic_modeling_pta.html#stopword",
    "href": "topic_modeling_pta.html#stopword",
    "title": "2  Topic Modeling PTA",
    "section": "5.3 Stopword",
    "text": "5.3 Stopword\nRemove Stopword adalah tahap yang melibatkan penghapusan kata-kata umum yang dianggap tidak memberikan nilai signifikan dalam analisis teks. Kata-kata semacam ini disebut stop words karena mereka sering muncul dalam teks bahasa alami tanpa memberikan informasi penting tentang isi atau makna teks. Contoh kata-kata umum ini termasuk “dan”, “atau”, “di”, “dari”, “yang”,” itu”, dan sebagainya. Penghapusan stop words bertujuan untuk mengurangi ukuran teks, mempercepat pemrosesan, dan meningkatkan relevansi informasi yang diambil dari teks, sehingga hanya kata kunci yang membentuk topik yang akan diekstraksi.\n\ndef process_stopword_token(tokens):\n    stop_words = set(stopwords.words(\"indonesian\"))\n    custom_stop_words = ['masingmasing','tiaptiap','satusatunya', 'intinya', 'seiring']\n    stop_words.update(custom_stop_words)\n    filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n    return \" \".join(filtered_tokens)\n\nstopword_abstrak = punctuation_abstrak.apply(process_stopword_token)\nstopword_abstrak\n\n0      sistem informasi akademik siakad sistem inform...\n1      berjalannya koneksi jaringan komputer lancar g...\n2      web server perangkat lunak server berfungsi me...\n3      penjadwalan kuliah perguruan kompleks permasal...\n4      perkembangan teknologi didunia muncul teknolog...\n                             ...                        \n826    investasi saham memiliki resiko kerugian perge...\n827    information retrieval ir pengambilan informasi...\n828    klasifikasi citra proses pengelompokan piksel ...\n829    identifikasi atribut pejalan kaki salah peneli...\n830    topik deteksi objek menarik perhatian perkemba...\nName: abstrak, Length: 831, dtype: object"
  },
  {
    "objectID": "topic_modeling_pta.html#steeming",
    "href": "topic_modeling_pta.html#steeming",
    "title": "2  Topic Modeling PTA",
    "section": "5.4 Steeming",
    "text": "5.4 Steeming\nStemming merupakan proses untuk mengurangi kata-kata ke bentuk dasarnya atau akar kata. Tujuannya adalah untuk mengidentifikasi kata-kata yang memiliki akar yang sama, meskipun mereka mungkin memiliki akhiran atau imbuhan yang berbeda\n\ndef process_stemming(text):\n    factory = StemmerFactory()\n    stemmer = factory.create_stemmer()\n    return stemmer.stem(text)\n\nsteeming_abstrak = stopword_abstrak.apply(process_stemming)\nsteeming_abstrak\n\n0      sistem informasi akademik siakad sistem inform...\n1      jalan koneksi jaring komputer lancar ganggu ha...\n2      web server perangkat lunak server fungsi terim...\n3      jadwal kuliah guru kompleks masalah variabel t...\n4      kembang teknologi dunia muncul teknologi augme...\n                             ...                        \n826    investasi saham milik resiko rugi gera harga s...\n827    information retrieval ir ambil informasi simpa...\n828    klasifikasi citra proses kelompok piksel citra...\n829    identifikasi atribut pejal kaki salah teliti k...\n830    topik deteksi objek tarik perhati kembang tekn...\nName: abstrak, Length: 831, dtype: object\n\n\n\ndf['stopword-abstrak'] = stopword_abstrak\ndf['steeming-abstrak'] = steeming_abstrak\ndf.to_csv('/content/drive/My Drive/Study Of Informatika/Pencarian dan Penambangan Web/Tugas 1/data/processing-data/preprocessing.csv', index=False)"
  },
  {
    "objectID": "topic_modeling_pta.html#local-weighting",
    "href": "topic_modeling_pta.html#local-weighting",
    "title": "2  Topic Modeling PTA",
    "section": "6.1 Local Weighting",
    "text": "6.1 Local Weighting\n\ncountvectorizer = CountVectorizer(analyzer= 'word')\nterm_matrix = countvectorizer.fit_transform(get_steeming_abstrak)\ncount_tokens = countvectorizer.get_feature_names_out()\ndf_countvect = pd.DataFrame(data = term_matrix.toarray(),columns = count_tokens)\nprint('Term Frequency\\n')\ndf_countvect\n\n# Transpose DataFrame\n# df_countvect_transposed = df_countvect.T\n\n# Print transposed DataFrame\n# print('Term Frequency Transposed\\n')\n# df_countvect_transposed\n\nTerm Frequency\n\n\n\n\n  \n    \n\n\n\n\n\n\naalysis\naam\nab\nabad\nabadi\nabai\nabdi\nability\nabjad\nabsah\n...\nzara\nzat\nzcz\nzf\nzona\nzone\nzoning\nzoom\nzucara\nzungu\n\n\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n2\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n4\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n826\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n827\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n828\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n829\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n830\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n\n831 rows × 6590 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\ncountvectorizer = CountVectorizer(analyzer='word')\n\nlog_matrix = countvectorizer.fit_transform(get_steeming_abstrak)\ncount_tokens = countvectorizer.get_feature_names_out()\n\ncount_log_matrix = np.log1p(log_matrix)\n\ndf_log_countvect = pd.DataFrame(data=count_log_matrix.toarray(), columns=count_tokens)\n\nprint('Log Frequency\\n')\ndf_log_countvect\n\nLog Frequency\n\n\n\n\n  \n    \n\n\n\n\n\n\naalysis\naam\nab\nabad\nabadi\nabai\nabdi\nability\nabjad\nabsah\n...\nzara\nzat\nzcz\nzf\nzona\nzone\nzoning\nzoom\nzucara\nzungu\n\n\n\n\n0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n1\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n2\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n3\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n4\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n826\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n827\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n828\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n829\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n830\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n\n\n\n831 rows × 6590 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\ncountvectorizer = CountVectorizer(analyzer='word', binary=True)\n\nbinary_matrix = countvectorizer.fit_transform(get_steeming_abstrak)\ndf_binary = pd.DataFrame(binary_matrix.toarray(), columns=countvectorizer.get_feature_names_out())\n\nprint('Binary\\n')\ndf_binary\n\nBinary\n\n\n\n\n  \n    \n\n\n\n\n\n\naalysis\naam\nab\nabad\nabadi\nabai\nabdi\nability\nabjad\nabsah\n...\nzara\nzat\nzcz\nzf\nzona\nzone\nzoning\nzoom\nzucara\nzungu\n\n\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n2\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n4\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n826\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n827\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n828\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n829\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n830\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n\n831 rows × 6590 columns"
  },
  {
    "objectID": "topic_modeling_pta.html#tf-idf",
    "href": "topic_modeling_pta.html#tf-idf",
    "title": "2  Topic Modeling PTA",
    "section": "6.2 TF-IDF",
    "text": "6.2 TF-IDF\nTF-IDF adalah teknik yang digunakan untuk mengukur pentingnya kata-kata dalam suatu dokumen dalam konteks korpus dokumen yang lebih besar. Ini dapat digunakan untuk mengidentifikasi kata-kata kunci atau fitur penting dalam analisis teks dan Natural Language Processing\n\ntfidfvectorizer = TfidfVectorizer(analyzer='word')\ntfidf = tfidfvectorizer.fit_transform(get_steeming_abstrak)\ntfidf_tokens = tfidfvectorizer.get_feature_names_out()\ntfidf_df = pd.DataFrame(data = tfidf.toarray(), columns = tfidf_tokens)\ntfidf_label = pd.concat([tfidf_df, data['label-topic']], axis=1)\ntfidf_label\n\n\n  \n    \n\n\n\n\n\n\naalysis\naam\nab\nabad\nabadi\nabai\nabdi\nability\nabjad\nabsah\n...\nzat\nzcz\nzf\nzona\nzone\nzoning\nzoom\nzucara\nzungu\nlabel-topic\n\n\n\n\n0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\nrpl\n\n\n1\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\nrpl\n\n\n2\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\nrpl\n\n\n3\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\nkomputasi\n\n\n4\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\nkomputasi\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n826\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\nkomputasi\n\n\n827\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\nkomputasi\n\n\n828\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\nkomputasi\n\n\n829\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\nkomputasi\n\n\n830\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\nkomputasi\n\n\n\n\n\n831 rows × 6591 columns"
  },
  {
    "objectID": "topic_modeling_pta.html#lda-topic",
    "href": "topic_modeling_pta.html#lda-topic",
    "title": "2  Topic Modeling PTA",
    "section": "6.3 LDA Topic",
    "text": "6.3 LDA Topic\n\ndocument = get_stopword_abstrak.apply(lambda x: x.split())\ndictionary = corpora.Dictionary(document)\ncorpus = [dictionary.doc2bow(tokens) for tokens in document]\n\nnum_topics = 3\nlda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n                                           id2word=dictionary,\n                                           num_topics=num_topics,\n                                           random_state=100,\n                                           passes=10,\n                                           per_word_topics=True)\n\n\nprint(lda_model.print_topics())\ndoc_lda = lda_model[corpus]\n\n[(0, '0.021*\"citra\" + 0.016*\"metode\" + 0.013*\"hasil\" + 0.013*\"penelitian\" + 0.011*\"proses\" + 0.010*\"game\" + 0.010*\"sistem\" + 0.009*\"data\" + 0.009*\"akurasi\" + 0.009*\"fitur\"'), (1, '0.028*\"sistem\" + 0.017*\"metode\" + 0.014*\"data\" + 0.013*\"hasil\" + 0.010*\"keputusan\" + 0.009*\"nilai\" + 0.008*\"penelitian\" + 0.008*\"proses\" + 0.008*\"informasi\" + 0.007*\"siswa\"'), (2, '0.013*\"data\" + 0.012*\"sistem\" + 0.011*\"hasil\" + 0.011*\"metode\" + 0.011*\"informasi\" + 0.009*\"aplikasi\" + 0.009*\"nilai\" + 0.007*\"proses\" + 0.007*\"jaringan\" + 0.006*\"penelitian\"')]\n\n\n\ntopic_proportions_list = []\n\nfor index, doc in enumerate(corpus):\n      topic_prop = lda_model.get_document_topics(doc)\n      proportions = {f'Topic {i+1}': 0.0 for i in range(num_topics)}\n\n      for topic in topic_prop:\n          proportions[f'Topic {topic[0] + 1}'] = topic[1]\n      topic_proportions_list.append(proportions)\n\ntopic_proportions = pd.DataFrame(topic_proportions_list)\ntopic_proportions_df = pd.DataFrame(topic_proportions_list)\ntopic_proportions_df.insert(0, 'judul', df['judul'])\ntopic_proportions_df.insert(4, 'label-topic', df['label-topic'])\ntopic_proportions_df\n\n\n  \n    \n\n\n\n\n\n\njudul\nTopic 1\nTopic 2\nTopic 3\nlabel-topic\n\n\n\n\n0\nPERANCANGAN DAN IMPLEMENTASI SISTEM DATABASE T...\n0.000000\n0.831309\n0.163884\nrpl\n\n\n1\nAPLIKASI KONTROL DAN MONITORING JARINGAN KOMPU...\n0.000000\n0.000000\n0.993200\nrpl\n\n\n2\nRANCANG BANGUN APLIKASI PROXY SERVER UNTUK\\nEN...\n0.542891\n0.000000\n0.453805\nrpl\n\n\n3\nSISTEM PENDUKUNG KEPUTUSAN OPTIMASI PENJADWALA...\n0.000000\n0.000000\n0.988820\nkomputasi\n\n\n4\nSISTEM AUGMENTED REALITY ANIMASI BENDA BERGERA...\n0.000000\n0.000000\n0.989163\nkomputasi\n\n\n...\n...\n...\n...\n...\n...\n\n\n826\nPENERAPAN ALGORITMA LONG-SHORT TERM MEMORY UNT...\n0.239679\n0.000000\n0.757095\nkomputasi\n\n\n827\nSISTEM PENCARIAN TEKS AL-QURAN TERJEMAHAN BERB...\n0.568052\n0.000000\n0.427201\nkomputasi\n\n\n828\nKLASIFIKASI KOMPLEKSITAS VISUAL CITRA SAMPAH M...\n0.995387\n0.000000\n0.000000\nkomputasi\n\n\n829\nIDENTIFIKASI BINER ATRIBUT PEJALAN KAKI MENGGU...\n0.994435\n0.000000\n0.000000\nkomputasi\n\n\n830\nDETEKSI OBJEK MANUSIA BERBASIS ONE STAGE DETEC...\n0.991774\n0.000000\n0.000000\nkomputasi\n\n\n\n\n\n831 rows × 5 columns"
  },
  {
    "objectID": "topic_modeling_pta.html#clustering-tf-idf",
    "href": "topic_modeling_pta.html#clustering-tf-idf",
    "title": "2  Topic Modeling PTA",
    "section": "7.1 Clustering TF-IDF",
    "text": "7.1 Clustering TF-IDF\n\ntfidf_clusters = kmeans_clustering(tfidf_df.values)\nsilhouette_tfidf = silhouette_score(tfidf_df.values, tfidf_clusters)\n\ntfidf_clusters_df = pd.DataFrame({'cluster':tfidf_clusters})\ntfidf_clusters_df.insert(0, 'judul', data['judul'])\ntfidf_clusters_df.insert(2, 'label-topic', data['label-topic'])\n\ntfidf_clusters_df\n\n/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n\n\n\n  \n    \n\n\n\n\n\n\njudul\ncluster\nlabel-topic\n\n\n\n\n0\nPERANCANGAN DAN IMPLEMENTASI SISTEM DATABASE T...\n1\nrpl\n\n\n1\nAPLIKASI KONTROL DAN MONITORING JARINGAN KOMPU...\n1\nrpl\n\n\n2\nRANCANG BANGUN APLIKASI PROXY SERVER UNTUK\\nEN...\n1\nrpl\n\n\n3\nSISTEM PENDUKUNG KEPUTUSAN OPTIMASI PENJADWALA...\n1\nkomputasi\n\n\n4\nSISTEM AUGMENTED REALITY ANIMASI BENDA BERGERA...\n1\nkomputasi\n\n\n...\n...\n...\n...\n\n\n826\nPENERAPAN ALGORITMA LONG-SHORT TERM MEMORY UNT...\n1\nkomputasi\n\n\n827\nSISTEM PENCARIAN TEKS AL-QURAN TERJEMAHAN BERB...\n1\nkomputasi\n\n\n828\nKLASIFIKASI KOMPLEKSITAS VISUAL CITRA SAMPAH M...\n0\nkomputasi\n\n\n829\nIDENTIFIKASI BINER ATRIBUT PEJALAN KAKI MENGGU...\n1\nkomputasi\n\n\n830\nDETEKSI OBJEK MANUSIA BERBASIS ONE STAGE DETEC...\n1\nkomputasi\n\n\n\n\n\n831 rows × 3 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\nprint('Silhouette TF-IDF', silhouette_tfidf)\n\nSilhouette TF-IDF -0.005708632045599099"
  },
  {
    "objectID": "topic_modeling_pta.html#clustering-lda-topic",
    "href": "topic_modeling_pta.html#clustering-lda-topic",
    "title": "2  Topic Modeling PTA",
    "section": "7.2 Clustering LDA Topic",
    "text": "7.2 Clustering LDA Topic\n\ntopic_proportions_clusters = kmeans_clustering(topic_proportions.values)\nsilhouette_topic_proportions = silhouette_score(topic_proportions.values, topic_proportions_clusters)\n\ntopic_proportions_df = pd.DataFrame({'cluster':topic_proportions_clusters})\ntopic_proportions_df.insert(0, 'judul', data['judul'])\ntopic_proportions_df.insert(2, 'label-topic', data['label-topic'])\n\ntopic_proportions_df\n\n/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n\n\n\n  \n    \n\n\n\n\n\n\njudul\ncluster\nlabel-topic\n\n\n\n\n0\nPERANCANGAN DAN IMPLEMENTASI SISTEM DATABASE T...\n2\nrpl\n\n\n1\nAPLIKASI KONTROL DAN MONITORING JARINGAN KOMPU...\n0\nrpl\n\n\n2\nRANCANG BANGUN APLIKASI PROXY SERVER UNTUK\\nEN...\n1\nrpl\n\n\n3\nSISTEM PENDUKUNG KEPUTUSAN OPTIMASI PENJADWALA...\n0\nkomputasi\n\n\n4\nSISTEM AUGMENTED REALITY ANIMASI BENDA BERGERA...\n0\nkomputasi\n\n\n...\n...\n...\n...\n\n\n826\nPENERAPAN ALGORITMA LONG-SHORT TERM MEMORY UNT...\n0\nkomputasi\n\n\n827\nSISTEM PENCARIAN TEKS AL-QURAN TERJEMAHAN BERB...\n1\nkomputasi\n\n\n828\nKLASIFIKASI KOMPLEKSITAS VISUAL CITRA SAMPAH M...\n1\nkomputasi\n\n\n829\nIDENTIFIKASI BINER ATRIBUT PEJALAN KAKI MENGGU...\n1\nkomputasi\n\n\n830\nDETEKSI OBJEK MANUSIA BERBASIS ONE STAGE DETEC...\n1\nkomputasi\n\n\n\n\n\n831 rows × 3 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\nprint('Silhouette LDA', silhouette_topic_proportions)\n\nSilhouette LDA 0.7976753714213479"
  },
  {
    "objectID": "topic_modeling_pta.html#tf-idf-1",
    "href": "topic_modeling_pta.html#tf-idf-1",
    "title": "2  Topic Modeling PTA",
    "section": "8.1 TF-IDF",
    "text": "8.1 TF-IDF\n\nX = tfidf_df\ny = data['label-topic']\ny = y.replace({'komputasi': 1, 'rpl': 0})\n\ndef train_knn_classifier(k):\n\n    # train model knn\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n    knn_classifier = KNeighborsClassifier(n_neighbors=k)\n    knn_classifier.fit(X_train, y_train)\n\n    y_pred = knn_classifier.predict(X_test)\n\n\n    # confusion matrix\n    cm = confusion_matrix(y_test, y_pred)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n\n    plt.figure(figsize=(4, 3))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    plt.title(f'Confusion Matrix for k = {k}')\n    plt.show()\n\n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred)\n    f1 = f1_score(y_test, y_pred)\n\n    print(\n      '\\nHasil Evaluasi Nilai K adalah',k,\n      '\\nAccuracy =', accuracy,\n      '\\nPrecision =', precision,\n      '\\nRecall =', recall,\n      '\\nF1 Score =', f1\n    )\n\n\ntrain_knn_classifier(3)\n\n\n\n\n\nHasil Evaluasi Nilai K adalah 3 \nAccuracy = 0.8083832335329342 \nPrecision = 0.8161764705882353 \nRecall = 0.940677966101695 \nF1 Score = 0.8740157480314961\n\n\n\ntrain_knn_classifier(5)\n\n\n\n\n\nHasil Evaluasi Nilai K adalah 5 \nAccuracy = 0.8143712574850299 \nPrecision = 0.8372093023255814 \nRecall = 0.9152542372881356 \nF1 Score = 0.8744939271255062\n\n\n\ntrain_knn_classifier(7)\n\n\n\n\n\nHasil Evaluasi Nilai K adalah 7 \nAccuracy = 0.8083832335329342 \nPrecision = 0.8359375 \nRecall = 0.9067796610169492 \nF1 Score = 0.8699186991869919\n\n\n\ntrain_knn_classifier(9)\n\n\n\n\n\nHasil Evaluasi Nilai K adalah 9 \nAccuracy = 0.8323353293413174 \nPrecision = 0.8515625 \nRecall = 0.923728813559322 \nF1 Score = 0.8861788617886179"
  },
  {
    "objectID": "topic_modeling_pta.html#lda-topic-1",
    "href": "topic_modeling_pta.html#lda-topic-1",
    "title": "2  Topic Modeling PTA",
    "section": "8.2 LDA Topic",
    "text": "8.2 LDA Topic\n\nX = topic_proportions\ny = data['label-topic']\ny = y.replace({'komputasi': 1, 'rpl': 0})\n\ndef train_knn_lda_classifier(k):\n\n    # train model knn\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n    knn_classifier = KNeighborsClassifier(n_neighbors=k)\n    knn_classifier.fit(X_train, y_train)\n\n    y_pred = knn_classifier.predict(X_test)\n\n\n    # confusion matrix\n    cm = confusion_matrix(y_test, y_pred)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n\n    plt.figure(figsize=(4, 3))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    plt.title(f'Confusion Matrix for k = {k}')\n    plt.show()\n\n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred)\n    f1 = f1_score(y_test, y_pred)\n\n    print(\n      '\\nHasil Evaluasi Nilai K adalah',k,\n      '\\nAccuracy =', accuracy,\n      '\\nPrecision =', precision,\n      '\\nRecall =', recall,\n      '\\nF1 Score =', f1\n    )\n\n\ntrain_knn_lda_classifier(3)\n\n\n\n\n\nHasil Evaluasi Nilai K adalah 3 \nAccuracy = 0.6347305389221557 \nPrecision = 0.7663551401869159 \nRecall = 0.6949152542372882 \nF1 Score = 0.7288888888888889\n\n\n\ntrain_knn_lda_classifier(5)\n\n\n\n\n\nHasil Evaluasi Nilai K adalah 5 \nAccuracy = 0.6586826347305389 \nPrecision = 0.7606837606837606 \nRecall = 0.7542372881355932 \nF1 Score = 0.7574468085106383\n\n\n\ntrain_knn_lda_classifier(7)\n\n\n\n\n\nHasil Evaluasi Nilai K adalah 7 \nAccuracy = 0.6407185628742516 \nPrecision = 0.7457627118644068 \nRecall = 0.7457627118644068 \nF1 Score = 0.7457627118644068\n\n\n\ntrain_knn_lda_classifier(9)\n\n\n\n\n\nHasil Evaluasi Nilai K adalah 9 \nAccuracy = 0.6706586826347305 \nPrecision = 0.7647058823529411 \nRecall = 0.7711864406779662 \nF1 Score = 0.7679324894514766"
  },
  {
    "objectID": "crawl_berita_cnn.html",
    "href": "crawl_berita_cnn.html",
    "title": "3  Crawl Berita CNN",
    "section": "",
    "text": "!pip install requests\n!pip install beautifulsoup4\n!pip install tqdm\n\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.7.22)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\nRequirement already satisfied: soupsieve&gt;1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n\n\n\nimport requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nfrom tqdm.auto import tqdm\n\n\n4 Crawling Data\nTeknik crawling data adalah proses pengumpulan informasi dari berbagai sumber di internet secara otomatis. Crawling data dilakukan oleh program yang disebut “web crawler”. Web crawler pada proses ini menggunakan beautifulsoup untuk melakukan ekstraksi halaman konten tersebut agar dapat mengambil isi-isi konten pada berita di website CNN Indonesia. Terdapat juga libraly request yang digunakan untuk meminta respon pada situs yang akan dilakukan crawling data.\n\nfrom os import replace\ndef cnnnews(page):\n\n    data = {'judul': [], 'berita': []}\n    for i in tqdm(range(1, page+1)):\n      url = f\"https://www.cnnindonesia.com/nasional/indeks/3/{i}\"\n      r = requests.get(url)\n      request = r.content\n      soup = BeautifulSoup(request, 'html.parser')\n      soup = soup.find('div', {'class': 'flex flex-col gap-5'})\n      news = soup.findAll('article', {'class': 'flex-grow'})\n      # news = soup.findAll('a', {'aria-label': 'link description'})\n\n      for new in tqdm(news):\n        a_element = new.find('a', {'aria-label': 'link description'})['href']\n        detail_request = requests.get(a_element)\n        detail_soup = BeautifulSoup(detail_request.content, 'html.parser')\n\n        judul = detail_soup.find('h1', {'class': 'leading-9'})\n        berita = detail_soup.find('div', {'class': 'detail-text'})\n\n        if judul and berita:\n          judul = judul.text\n          berita = berita.text\n          noise = detail_soup.find('strong').text\n\n          berita = berita.replace(\"ADVERTISEMENT\", \"\").replace(\"SCROLL TO CONTINUE WITH CONTENT\", \"\").replace(\"Lihat Juga :\", \"\").replace(\"Bagikan\", \"\").replace(noise, \"\").replace(\"-- \", \"\").replace(\"--\", \"\")\n          berita = ' '.join(berita.split())\n          data[\"judul\"].append(judul)\n          data[\"berita\"].append(berita)\n\n    df = pd.DataFrame(data)\n    df.to_csv(\"berita-cnn.csv\", index=False)\n\n    return df\n\n\ncnnnews(5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n\n\n\n\n\n\njudul\nberita\n\n\n\n\n0\nDirjen Kemendagri Safrizal ZA Jadi Pj Gubernu...\nMenteri Dalam Negeri (Mendagri) Tito Karnavian...\n\n\n1\nGanjar Temui Gus Mus di Rembang, Bahas Polemi...\nBakal capres PDIP Ganjar Pranowo mengunjungi k...\n\n\n2\nNomor Urut Capres-Cawapres Diundi KPU Besok\nKomisi Pemilihan Umum (KPU) RI bakal melaksana...\n\n\n3\nUtut Adianto Pimpin Panja Netralitas TNI di P...\nKomisi I DPR sudah menyepakati pembentukan Pan...\n\n\n4\nIstri Cak Nur Curhat ke Gus Mus: Nepotisme Di...\nSejumlah tokoh bangsa yang mengatasnamakan dir...\n\n\n5\nEks Stafsus SBY Velix Wanggai Jadi Pj Gubernu...\nPresiden Joko Widodo menunjuk mantan Staf Khus...\n\n\n6\nKPU Resmi Tetapkan Prabowo, Ganjar, Anies seb...\nKomisi Pemilihan Umum (KPU) resmi menetapkan t...\n\n\n7\nEks Kadis PUPR Papua Didakwa Terima Suap & Gr...\nKepala Dinas Pekerjaan Umum dan Perumahan Raky...\n\n\n8\nFatia Maulidiyanti Dituntut 3,5 Tahun Penjara...\nAktivitis Hak Asasi Manusia (HAM) Fatia Maulid...\n\n\n9\nKPK Panggil Keponakan SYL Istri Kapolrestabes...\nKomisi Pemberantasan Korupsi (KPK) memanggil k...\n\n\n10\nHaris Azhar Dituntut 4 Tahun Penjara Kasus Lo...\nAktivitis Hak Asasi Manusia (HAM) Haris Azhar ...\n\n\n11\nKPK Dalami Dugaan Kartu Anggota Kasino SYL\nKomisi Pemberantasan Korupsi (KPK) tengah mend...\n\n\n12\nPelecehan Anggota BEM UNY Hoaks, Polisi Tangk...\nPolisi memastikan dugaan kasus pelecehan mahas...\n\n\n13\nDinkes DKI: Kasus Cacar Monyet di Jakarta Cap...\nDinas Kesehatan (Dinkes) DKI Jakarta melaporka...\n\n\n14\nPemkab Ungkap Susun 6 Dimensi pada Perencanaa...\nKabupaten Klaten menyatakan memiliki enam dime...\n\n\n15\nSri Mulyani Sebut Petugas Kesehatan Merupakan...\nPemerintah Kabupaten Klaten menggelar Upacara ...\n\n\n16\nKlaten Ambil Bagian pada Evaluasi Tahap II Sm...\nKabupaten Klaten turut ambil bagian sebagai sa...\n\n\n17\nPuncak Peringatan HKN Ke-59, Bupati Klaten Ap...\nBupati Klaten, Jawa Tengah, Sri Mulyani, menya...\n\n\n18\nNakes Klaten Diminta Jadi Pelopor Budaya Hidu...\nBupati Klaten, Sri Mulyani, meminta tenaga kes...\n\n\n19\nFOTO: Suhartoyo Resmi Jadi Ketua MK Gantikan ...\nHakim konstitusi Suhartoyo resmi dilantik seba...\n\n\n20\nFit and Proper Test Panglima TNI Singgung Isu...\nCalon Panglima TNI Jenderal Agus Subiyanto men...\n\n\n21\nKapolda Metro Sebut Tersangka Kasus Pemerasan...\nKapolda Metro Jaya Irjen Karyoto menyebut sege...\n\n\n22\nIrjen Karyoto soal Firli: Kita Lihat Saja Bes...\nKapolda Metro Jaya Irjen Karyoto angkat suara ...\n\n\n23\nSuhartoyo Janji Segera Bentuk MKMK Permanen\nKetua Mahkamah Konstitusi (MK) Suhartoyo berja...\n\n\n24\nMahfud Singgung Menteri Jokowi Ditangkap Koru...\nMenko Polhukam Mahfud MD menyinggung banyaknya...\n\n\n25\nMahfud Respons Dugaan Saling Sandera KPK-Pold...\nMenko Polhukam Mahfud MD angkat suara soal ada...\n\n\n26\nAgus Subiyanto di DPR: Jika Ingin Damai, Bers...\nKepala Staf Angkatan Darat (KSAD) sekaligus ca...\n\n\n27\nOTT KPK di Sorong Terkait Pengondisian Temuan...\nKomisi Pemberantasan Korupsi (KPK) mengungkapk...\n\n\n28\nKPK Total Tangkap 5 Orang Terkait OTT di Sorong\nKomisi Pemberantasan Korupsi (KPK) total menan...\n\n\n29\nAnwar Usman Absen di Pelantikan Ketua MK, Izi...\nHakim Konstitusi Anwar Usman tidak hadir dalam...\n\n\n30\nKPK Total Tangkap 5 Orang Terkait OTT di Sorong\nKomisi Pemberantasan Korupsi (KPK) total menan...\n\n\n31\nAnwar Usman Absen di Pelantikan Ketua MK, Izi...\nHakim Konstitusi Anwar Usman tidak hadir dalam...\n\n\n32\nKomisi I DPR Sepakati Agus Subiyanto Jadi Pan...\nKomisi I DPR secara resmi menyepakati KSAD Jen...\n\n\n33\nJelang Penetapan Capres-Cawapres, Jalan Depan...\nJalan Imam Bonjol depan kantor Komisi Pemiliha...\n\n\n34\nMassa Atribut Serba Hitam Demo di KPU Jelang ...\nDemonstrasi terjadi di depan kantor Komisi Pem...\n\n\n35\nPAN Solid Dukung Prabowo-Gibran dan Menang Pi...\nWakil Bendahara Umum Partai Amanat Nasional (P...\n\n\n36\nLHKPN Ketua MK Suhartoyo, Punya Harta Rp14,7 ...\nKetua Mahkamah Konstitusi (MK) terpilih pengga...\n\n\n37\nFit & Proper Test, Agus Janji Ingatkan Prajur...\nCalon Panglima TNI Jenderal Agus Subiyanto ber...\n\n\n38\nYasonna soal Wamenkumham Jadi Tersangka: Sila...\nMenteri Hukum dan Hak Asasi Manusia (Menkumham...\n\n\n39\nKetua MK Suhartoyo Menangis Saat Pidato Soal ...\nHakim Mahkamah Konstitusi (MK) Suhartoyo menan...\n\n\n40\nBahlil Heran Gibran Dipersoalkan: Banyak Ment...\nKetua Dewan Pembina Relawan Pengusaha Nasional...\n\n\n41\nGibran: Laporkan Saja ke Bawaslu Jika Ada Kec...\nWali Kota Solo sekaligus bakal cawapres Gibran...\n\n\n42\nBupati Dhito: Batik Kediri Siap Masuk Kancah ...\nBupati Kediri Hanindhito Himawan Pramana menya...\n\n\n43\nSempat Macet Parah, Jalan Mampang Prapatan Ar...\nKemacetan sempat terjadi di Jalan Mampang Prap...\n\n\n44\nPejabat Sorong dan Pegawai BPK Terjaring OTT ...\nKomisi Pemberantasan Korupsi (KPK) melakukan o...\n\n\n45\nFit and Proper Test Calon Panglima TNI, Jende...\nKepala Staf Angkatan Darat (KSAD) sekaligus ca...\n\n\n46\nVIDEO: Momen Suhartoyo Resmi Dilantik Jadi Ke...\nMahkamah Konstitusi resmi melantik Suhartoyo m...\n\n\n47\nWali Kota Semarang Ingin Masyarakat Tak Berga...\nFestival pangan pendamping beras bertajuk Prom...\n\n\n48\nPanglima TNI-Kapolri ke Rumah Agus Subiyanto ...\nPanglima TNI Laksamana Yudo Margono dan Kapolr...\n\n\n49\nSuhartoyo Resmi Jadi Ketua MK Gantikan Anwar ...\nHakim konstitusi Suhartoyo resmi dilantik seba..."
  },
  {
    "objectID": "news_summarization.html",
    "href": "news_summarization.html",
    "title": "4  Ringkasan Berita",
    "section": "",
    "text": "5 Instalasi\n!pip install rouge\n\nRequirement already satisfied: rouge in /usr/local/lib/python3.10/dist-packages (1.0.1)\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\nimport pandas as pd\nimport nltk\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom nltk.corpus import stopwords\nfrom rouge import Rouge\nnltk.download('punkt')\nnltk.download(\"stopwords\")\n\n[nltk_data] Downloading package punkt to /root/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n\n\nTrue\nData yang digunakan menggunakan hasil crawling data pada website CNN Indonesia dalam kategori berita nasional.\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\ncsv_path = '/content/drive/My Drive/Task/Pencarian dan Penambangan Web/Tugas 2/data/berita-cnn.csv'\ndf = pd.read_csv(csv_path)\ndf\n\nDrive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n\n\n\n  \n    \n\n\n\n\n\n\njudul\nberita\n\n\n\n\n0\nDirjen Kemendagri Safrizal ZA Jadi Pj Gubernu...\nMenteri Dalam Negeri (Mendagri) Tito Karnavian...\n\n\n1\nGanjar Temui Gus Mus di Rembang, Bahas Polemi...\nBakal capres PDIP Ganjar Pranowo mengunjungi k...\n\n\n2\nNomor Urut Capres-Cawapres Diundi KPU Besok\nKomisi Pemilihan Umum (KPU) RI bakal melaksana...\n\n\n3\nUtut Adianto Pimpin Panja Netralitas TNI di P...\nKomisi I DPR sudah menyepakati pembentukan Pan...\n\n\n4\nIstri Cak Nur Curhat ke Gus Mus: Nepotisme Di...\nSejumlah tokoh bangsa yang mengatasnamakan dir...\n\n\n5\nEks Stafsus SBY Velix Wanggai Jadi Pj Gubernu...\nPresiden Joko Widodo menunjuk mantan Staf Khus...\n\n\n6\nKPU Resmi Tetapkan Prabowo, Ganjar, Anies seb...\nKomisi Pemilihan Umum (KPU) resmi menetapkan t...\n\n\n7\nEks Kadis PUPR Papua Didakwa Terima Suap & Gr...\nKepala Dinas Pekerjaan Umum dan Perumahan Raky...\n\n\n8\nFatia Maulidiyanti Dituntut 3,5 Tahun Penjara...\nAktivitis Hak Asasi Manusia (HAM) Fatia Maulid...\n\n\n9\nKPK Panggil Keponakan SYL Istri Kapolrestabes...\nKomisi Pemberantasan Korupsi (KPK) memanggil k...\n\n\n10\nHaris Azhar Dituntut 4 Tahun Penjara Kasus Lo...\nAktivitis Hak Asasi Manusia (HAM) Haris Azhar ...\n\n\n11\nKPK Dalami Dugaan Kartu Anggota Kasino SYL\nKomisi Pemberantasan Korupsi (KPK) tengah mend...\n\n\n12\nPelecehan Anggota BEM UNY Hoaks, Polisi Tangk...\nPolisi memastikan dugaan kasus pelecehan mahas...\n\n\n13\nDinkes DKI: Kasus Cacar Monyet di Jakarta Cap...\nDinas Kesehatan (Dinkes) DKI Jakarta melaporka...\n\n\n14\nPemkab Ungkap Susun 6 Dimensi pada Perencanaa...\nKabupaten Klaten menyatakan memiliki enam dime...\n\n\n15\nSri Mulyani Sebut Petugas Kesehatan Merupakan...\nPemerintah Kabupaten Klaten menggelar Upacara ...\n\n\n16\nKlaten Ambil Bagian pada Evaluasi Tahap II Sm...\nKabupaten Klaten turut ambil bagian sebagai sa...\n\n\n17\nPuncak Peringatan HKN Ke-59, Bupati Klaten Ap...\nBupati Klaten, Jawa Tengah, Sri Mulyani, menya...\n\n\n18\nNakes Klaten Diminta Jadi Pelopor Budaya Hidu...\nBupati Klaten, Sri Mulyani, meminta tenaga kes...\n\n\n19\nFOTO: Suhartoyo Resmi Jadi Ketua MK Gantikan ...\nHakim konstitusi Suhartoyo resmi dilantik seba...\n\n\n20\nFit and Proper Test Panglima TNI Singgung Isu...\nCalon Panglima TNI Jenderal Agus Subiyanto men...\n\n\n21\nKapolda Metro Sebut Tersangka Kasus Pemerasan...\nKapolda Metro Jaya Irjen Karyoto menyebut sege...\n\n\n22\nIrjen Karyoto soal Firli: Kita Lihat Saja Bes...\nKapolda Metro Jaya Irjen Karyoto angkat suara ...\n\n\n23\nSuhartoyo Janji Segera Bentuk MKMK Permanen\nKetua Mahkamah Konstitusi (MK) Suhartoyo berja...\n\n\n24\nMahfud Singgung Menteri Jokowi Ditangkap Koru...\nMenko Polhukam Mahfud MD menyinggung banyaknya...\n\n\n25\nMahfud Respons Dugaan Saling Sandera KPK-Pold...\nMenko Polhukam Mahfud MD angkat suara soal ada...\n\n\n26\nAgus Subiyanto di DPR: Jika Ingin Damai, Bers...\nKepala Staf Angkatan Darat (KSAD) sekaligus ca...\n\n\n27\nOTT KPK di Sorong Terkait Pengondisian Temuan...\nKomisi Pemberantasan Korupsi (KPK) mengungkapk...\n\n\n28\nKPK Total Tangkap 5 Orang Terkait OTT di Sorong\nKomisi Pemberantasan Korupsi (KPK) total menan...\n\n\n29\nAnwar Usman Absen di Pelantikan Ketua MK, Izi...\nHakim Konstitusi Anwar Usman tidak hadir dalam...\n\n\n30\nKPK Total Tangkap 5 Orang Terkait OTT di Sorong\nKomisi Pemberantasan Korupsi (KPK) total menan...\n\n\n31\nAnwar Usman Absen di Pelantikan Ketua MK, Izi...\nHakim Konstitusi Anwar Usman tidak hadir dalam...\n\n\n32\nKomisi I DPR Sepakati Agus Subiyanto Jadi Pan...\nKomisi I DPR secara resmi menyepakati KSAD Jen...\n\n\n33\nJelang Penetapan Capres-Cawapres, Jalan Depan...\nJalan Imam Bonjol depan kantor Komisi Pemiliha...\n\n\n34\nMassa Atribut Serba Hitam Demo di KPU Jelang ...\nDemonstrasi terjadi di depan kantor Komisi Pem...\n\n\n35\nPAN Solid Dukung Prabowo-Gibran dan Menang Pi...\nWakil Bendahara Umum Partai Amanat Nasional (P...\n\n\n36\nLHKPN Ketua MK Suhartoyo, Punya Harta Rp14,7 ...\nKetua Mahkamah Konstitusi (MK) terpilih pengga...\n\n\n37\nFit & Proper Test, Agus Janji Ingatkan Prajur...\nCalon Panglima TNI Jenderal Agus Subiyanto ber...\n\n\n38\nYasonna soal Wamenkumham Jadi Tersangka: Sila...\nMenteri Hukum dan Hak Asasi Manusia (Menkumham...\n\n\n39\nKetua MK Suhartoyo Menangis Saat Pidato Soal ...\nHakim Mahkamah Konstitusi (MK) Suhartoyo menan...\n\n\n40\nBahlil Heran Gibran Dipersoalkan: Banyak Ment...\nKetua Dewan Pembina Relawan Pengusaha Nasional...\n\n\n41\nGibran: Laporkan Saja ke Bawaslu Jika Ada Kec...\nWali Kota Solo sekaligus bakal cawapres Gibran...\n\n\n42\nBupati Dhito: Batik Kediri Siap Masuk Kancah ...\nBupati Kediri Hanindhito Himawan Pramana menya...\n\n\n43\nSempat Macet Parah, Jalan Mampang Prapatan Ar...\nKemacetan sempat terjadi di Jalan Mampang Prap...\n\n\n44\nPejabat Sorong dan Pegawai BPK Terjaring OTT ...\nKomisi Pemberantasan Korupsi (KPK) melakukan o...\n\n\n45\nFit and Proper Test Calon Panglima TNI, Jende...\nKepala Staf Angkatan Darat (KSAD) sekaligus ca...\n\n\n46\nVIDEO: Momen Suhartoyo Resmi Dilantik Jadi Ke...\nMahkamah Konstitusi resmi melantik Suhartoyo m...\n\n\n47\nWali Kota Semarang Ingin Masyarakat Tak Berga...\nFestival pangan pendamping beras bertajuk Prom...\n\n\n48\nPanglima TNI-Kapolri ke Rumah Agus Subiyanto ...\nPanglima TNI Laksamana Yudo Margono dan Kapolr...\n\n\n49\nSuhartoyo Resmi Jadi Ketua MK Gantikan Anwar ...\nHakim konstitusi Suhartoyo resmi dilantik seba...\nUntuk meringkas suatu dokumen, maka kita hanya memerlukan satu sampel berita yang akan digunakan dengan menggunakan berita pertama\nberita = df['berita'].iloc[0]\nPada analisis ringkasan dokumen kali ini akan menggunakan 2 metode pengujian, pengujian pertama akan dilakukan langkah ringkasan berita tanpa menggunakan preprocessing dan tahapan pengujian kedua berita yang diringkas akan menggunakan tahapan preprocessing. Tahapan preprocessing ini antara lain yaitu menghapus angka, simbol dan stopword pada berita.\ndef preprocessing(text):\n    text = re.sub(r'\\d+', '', text)\n    text = re.sub(r'[^\\w\\s.]', '', text)\n    text = text.lower()\n\n    stop_words = set(stopwords.words('indonesian'))\n    words = text.split()\n    filtered_words = [word for word in words if word.lower() not in stop_words]\n\n    preprocessing_text = ' '.join(filtered_words)\n\n    return preprocessing_text\nkalimat_preprocessing = preprocessing(berita)\nEkstraksi fitur pada tahapan ini menggunakan TF-IDF untuk membentuk vektor pada setiap kalimatnya, sedangkan fitur yang akan digunakan pada vektor TF-IDF ini meliputi term pada keseluruhan dokumen.\nkalimat = nltk.sent_tokenize(berita) #memecah dokumen berdasarkan kalimatnya tanpa preprocessing\nkalimat_preprocessing = nltk.sent_tokenize(kalimat_preprocessing) #memecah dokumen berdasarkan kalimatnya menggunakan preprocessing\nDalam meringkas dokumen ini diperlukan untuk membentuk graph sebagai gambaran antara kedekatan pada masing-masing kalimat, sehingga dalam ringkasan dokumen yang dihasilkan akan memunculkan kalimat-kalimat penting dan memiliki kedekatan di setiap dokumennya.\nMatriks Sentralitas adalah matriks yang digunakan untuk merepresentasikan ukuran sentralitas dari setiap node dalam jaringan. Sentralitas adalah konsep dalam analisis jaringan yang mencoba mengukur sejauh mana suatu node berada di pusat jaringan atau sejauh mana suatu node penting dalam graph. Beberapa matriks ini akan digunakan untuk membangun ringkasan dokumen yang dibuat oleh sistem, matriks ini didapatkan dari bentuk graph yang telah terbentuk pada langkah sebelumnya.\nROUGE (Recall-Oriented Understudy for Gisting Evaluation) adalah sekelompok metrik evaluasi otomatis yang umum digunakan untuk mengukur kualitas ringkasan teks. ROUGE memiliki beberapa varian, dan di antaranya, ROUGE-1, ROUGE-2, dan ROUGE-L merupakan metrik yang sering digunakan untuk mengukur sejauh mana kedekatan ringkasan sistem dengan ringkasan referensi.\n#referensi ringkasan yang dibuat secara manual\nreferensi = ['Menteri Dalam Negeri Tito Karnavian melantik Safrizal ZA sebagai Penjabat Gubernur Bangka Belitung dan Velix Vernando Wanggai sebagai Penjabat Gubernur Papua Pegunungan.Tito menugaskan kedua penjabat gubernur untuk menangani isu kemiskinan ekstrem, inflasi, stunting, infrastruktur, pendidikan, kesehatan, serta persoalan khusus di wilayah masing-masing. Tito menitipkan persiapan Pemilu Serentak dan Pilkada Serentak 2024 kepada mereka, dengan harapan agar dapat membantu Komisi Pemilihan Umum (KPU) serta menekankan koordinasi dengan bupati dan wali kota untuk menyelesaikan naskah perjanjian hibah daerah.',]\nprint(referensi)\n\n['Menteri Dalam Negeri Tito Karnavian melantik Safrizal ZA sebagai Penjabat Gubernur Bangka Belitung dan Velix Vernando Wanggai sebagai Penjabat Gubernur Papua Pegunungan.Tito menugaskan kedua penjabat gubernur untuk menangani isu kemiskinan ekstrem, inflasi, stunting, infrastruktur, pendidikan, kesehatan, serta persoalan khusus di wilayah masing-masing. Tito menitipkan persiapan Pemilu Serentak dan Pilkada Serentak 2024 kepada mereka, dengan harapan agar dapat membantu Komisi Pemilihan Umum (KPU) serta menekankan koordinasi dengan bupati dan wali kota untuk menyelesaikan naskah perjanjian hibah daerah.']\ndef rouge(referensi, hasil_ringkasan):\n    rouge = Rouge()\n    scores = rouge.get_scores(hasil_ringkasan, referensi)\n    print (scores)"
  },
  {
    "objectID": "news_summarization.html#tf-idf",
    "href": "news_summarization.html#tf-idf",
    "title": "4  Ringkasan Berita",
    "section": "8.1 TF-IDF",
    "text": "8.1 TF-IDF\nTerm Frequency-Inverse Document Frequency (TF-IDF) adalah vektor yang digunakan untuk mengevaluasi pentingnya kata-kata dalam sebuah dokumen. Nilai frekuensi kemunculan kata dalam setiap dokumen ini menunjukkan seberapa penting kata tersebut dalam dokumen. Berikut merupakan rumus untuk menghitung TF-IDF: \n\\[W_{d,t} = tf_{t,d} \\cdot idf_{t,d}\\]  Keterangan =  \\(W_{d,t}\\) = Nilai Term Frequency untuk term (t) dalam dokumen (d).  \\(tf_{t,d}\\) = Frekuensi kemunculan term (t) dalam dokumen (d).  \\(idf_{t,d}\\) = Inverse Document Frequency Nilai kebalikan frekuensi dokumen term (t) dalam dokumen (d). Pada dasarnya TF-IDF adalah gabungan dari Term Frequency (TF) dan Inverse Document Frequency (IDF) sehingga sebelum kita membentuk nilai TFIDF, maka kita harus menghitung kedua nilai tersebut. Term Frequency (TF) merupakan perhitungan yang digunakan untuk menentukan seberapa sering kata-kata muncul dalam sebuah dokumen. \\[tf= \\frac{tf}{max(tf)}\\]  Keterangan =  \\(tf\\) = banyaknya kata yang dicari dalam dokumen  \\(max⁡(tf)\\) = jumlah kemunculan term terbanyak pada dokumen yang sama \nSedangkan Inverse Document Frequency (IDF) menilai kata-kata yang sering muncul sebagai kurang signifikan karena kemunculannya dalam banyak dokumen. Semakin rendah nilai IDF, maka kata tersebut akan dianggap kurang berarti dan sebaliknya, semakin tinggi nilai IDF maka kata tersebut akan dianggap lebih relevan atau penting dalam dokumen tersebut.  \\[idf_{t}= \\frac{D}{max(df_{t})}\\]  Keterangan =  \\(D\\) = total dokumen  \\(df⁡(t)\\) = jumlah dokumen yang mengandung term (t) \nTF-IDF Tanpa Preprocessing\n\ntfidf_vectorizer = TfidfVectorizer()\ntfidf = tfidf_vectorizer.fit_transform(kalimat)\n\nterms = tfidf_vectorizer.get_feature_names_out()\ntfidf = pd.DataFrame(data=tfidf.toarray(), columns=terms)\n\ntfidf\n\n\n  \n    \n\n\n\n\n\n\n11\n13\n19\n2024\nadalah\nadministrasi\nadwil\nakan\nawasi\nbangka\n...\nvelix\nvernando\nvideo\nwakil\nwali\nwanggai\nwawasan\nwilayah\nyang\nza\n\n\n\n\n0\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.262213\n...\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.300296\n\n\n1\n0.269719\n0.269719\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n2\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.225098\n0.315524\n0.000000\n0.00000\n0.000000\n0.275510\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n3\n0.000000\n0.000000\n0.000000\n0.000000\n0.162701\n0.000000\n0.000000\n0.207738\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n0.000000\n0.000000\n0.000000\n0.415477\n0.000000\n\n\n4\n0.255375\n0.255375\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n5\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n6\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n0.000000\n0.000000\n0.314751\n0.000000\n0.000000\n\n\n7\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.232083\n...\n0.189617\n0.000000\n0.000000\n0.00000\n0.000000\n0.232083\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n8\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.261304\n0.000000\n0.000000\n0.00000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n9\n0.000000\n0.000000\n0.000000\n0.312276\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n10\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n11\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.00000\n0.178791\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n12\n0.000000\n0.000000\n0.000000\n0.000000\n0.194693\n0.248586\n0.248586\n0.000000\n0.248586\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n13\n0.000000\n0.000000\n0.279549\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n14\n0.000000\n0.000000\n0.000000\n0.000000\n0.279706\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.254781\n0.000000\n0.000000\n0.31184\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n15\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.23924\n0.000000\n0.000000\n0.273986\n0.000000\n0.000000\n0.000000\n\n\n16\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.447214\n0.00000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n\n\n\n17 rows × 172 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\nTF-IDF Menggunakan Preprocessing\n\ntfidf_vectorizer = TfidfVectorizer()\ntfidf_preprocessing = tfidf_vectorizer.fit_transform(kalimat_preprocessing)\n\nterms = tfidf_vectorizer.get_feature_names_out()\ntfidf_preprocessing = pd.DataFrame(data=tfidf_preprocessing.toarray(), columns=terms)\n\ntfidf_preprocessing\n\n\n  \n    \n\n\n\n\n\n\nadministrasi\nadwil\nawasi\nbangka\nbapakbapak\nbelitung\nberharap\nberjalan\nberperan\nbersamaan\n...\ntolong\ntugas\nvelix\nvernando\nwakil\nwali\nwanggai\nwawasan\nwilayah\nza\n\n\n\n\n0\n0.000000\n0.000000\n0.000000\n0.294052\n0.0000\n0.294052\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.0000\n0.000000\n0.000000\n0.000000\n0.000000\n0.0000\n0.000000\n0.000000\n0.000000\n0.336759\n\n\n1\n0.000000\n0.000000\n0.000000\n0.000000\n0.0000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.0000\n0.000000\n0.000000\n0.000000\n0.000000\n0.0000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n2\n0.000000\n0.000000\n0.000000\n0.000000\n0.0000\n0.000000\n0.000000\n0.000000\n0.000000\n0.387236\n...\n0.0000\n0.000000\n0.276258\n0.387236\n0.000000\n0.0000\n0.338128\n0.000000\n0.000000\n0.000000\n\n\n3\n0.000000\n0.000000\n0.000000\n0.000000\n0.0000\n0.000000\n0.308065\n0.000000\n0.000000\n0.000000\n...\n0.0000\n0.308065\n0.000000\n0.000000\n0.000000\n0.0000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n4\n0.000000\n0.000000\n0.000000\n0.000000\n0.0000\n0.000000\n0.000000\n0.380838\n0.000000\n0.000000\n...\n0.0000\n0.000000\n0.000000\n0.000000\n0.000000\n0.0000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n5\n0.000000\n0.000000\n0.000000\n0.000000\n0.0000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.0000\n0.000000\n0.000000\n0.000000\n0.000000\n0.0000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n6\n0.000000\n0.000000\n0.000000\n0.000000\n0.0000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.0000\n0.000000\n0.000000\n0.000000\n0.000000\n0.0000\n0.000000\n0.000000\n0.515543\n0.000000\n\n\n7\n0.000000\n0.000000\n0.000000\n0.260917\n0.0000\n0.260917\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.0000\n0.000000\n0.213175\n0.000000\n0.000000\n0.0000\n0.260917\n0.000000\n0.000000\n0.000000\n\n\n8\n0.000000\n0.000000\n0.000000\n0.000000\n0.0000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.0000\n0.411704\n0.336372\n0.000000\n0.000000\n0.0000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n9\n0.000000\n0.000000\n0.000000\n0.000000\n0.0000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.0000\n0.000000\n0.000000\n0.000000\n0.000000\n0.0000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n10\n0.000000\n0.000000\n0.000000\n0.000000\n0.0000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.0000\n0.000000\n0.000000\n0.000000\n0.000000\n0.0000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n11\n0.000000\n0.000000\n0.000000\n0.000000\n0.2477\n0.000000\n0.216287\n0.000000\n0.000000\n0.000000\n...\n0.2477\n0.000000\n0.000000\n0.000000\n0.000000\n0.2477\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n12\n0.261989\n0.261989\n0.261989\n0.000000\n0.0000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.0000\n0.000000\n0.000000\n0.000000\n0.000000\n0.0000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n13\n0.000000\n0.000000\n0.000000\n0.000000\n0.0000\n0.000000\n0.000000\n0.000000\n0.358922\n0.000000\n...\n0.0000\n0.000000\n0.000000\n0.000000\n0.000000\n0.0000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n14\n0.000000\n0.000000\n0.000000\n0.000000\n0.0000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.0000\n0.000000\n0.317972\n0.000000\n0.389184\n0.0000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n15\n0.000000\n0.000000\n0.000000\n0.000000\n0.0000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.0000\n0.000000\n0.000000\n0.000000\n0.251545\n0.0000\n0.000000\n0.288078\n0.000000\n0.000000\n\n\n16\n0.000000\n0.000000\n0.000000\n0.000000\n0.0000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.0000\n0.000000\n0.000000\n0.000000\n0.000000\n0.0000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n\n\n\n17 rows × 121 columns"
  },
  {
    "objectID": "news_summarization.html#cosine-similarity",
    "href": "news_summarization.html#cosine-similarity",
    "title": "4  Ringkasan Berita",
    "section": "9.1 Cosine Similarity",
    "text": "9.1 Cosine Similarity\nCosine similarity digunakan untuk mengukur seberapa mirip dua vektor dalam ruang berdimensi banyak. Hasil dari cosine similarity ini akan menentukan apakah vektor tersebut menuju ke arah yang sama. Semakin kecil sudut antara dua vektor, maka semakin mirip satu sama lain sedangkan begitu juga sebaliknya, semakin besar nilai cosine similarity maka vektor tersebut dianggap jauh kemiripannya. Dalam ringkasan dokumen ini penting untuk menghitung nilai cosine similarity untuk mengetahui hubungan kesamaan antara kalimat satu dengan kalimat lainnya. Vektor yang digunakan untuk menghitung nilai cosine simmilarity ini adalah hasil dari TF-IDF pada langkah sebelumnya. Berikut merupakan rumus yang digunakan untuk menghitung nilai cosine simmilarity. \\[simmilarity(A, B) = \\frac{A \\cdot B}{|A||B|}\\] \nKeterangan =  A.B = Vector dot product dari A dan B dihitung dengan \\(\\sum_{i=1}^n x_{k}y_{k}\\)  |A| = Panjang vektor A dihitung dengan \\(\\sum_{i=1}^n x_{k}^2\\)  |B| = Panjang vektor A dihitung dengan \\(\\sum_{i=1}^n y_{k}^2\\) \nCosine Similarity Tanpa Preprocessing\n\ncosine = cosine_similarity(tfidf, tfidf)\n\n\nsimilarity = pd.DataFrame(cosine, columns=range(len(kalimat)), index=range(len(kalimat)))\nsimilarity\n\n\n  \n    \n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n\n\n\n0\n1.000000\n0.000000\n0.183156\n0.031750\n0.077184\n0.106877\n0.000000\n0.234579\n0.000000\n0.034685\n0.116650\n0.067043\n0.077952\n0.042725\n0.000000\n0.000000\n0.0\n\n\n1\n0.000000\n1.000000\n0.000000\n0.000000\n0.206638\n0.000000\n0.041888\n0.035372\n0.048745\n0.000000\n0.000000\n0.000000\n0.058545\n0.000000\n0.047528\n0.000000\n0.0\n\n\n2\n0.183156\n0.000000\n1.000000\n0.000000\n0.034132\n0.112296\n0.060918\n0.276659\n0.200600\n0.096883\n0.032666\n0.041731\n0.033793\n0.000000\n0.057351\n0.000000\n0.0\n\n\n3\n0.031750\n0.000000\n0.000000\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.058014\n0.000000\n0.029594\n0.075541\n0.031677\n0.044278\n0.045509\n0.000000\n0.0\n\n\n4\n0.077184\n0.206638\n0.034132\n0.000000\n1.000000\n0.032889\n0.000000\n0.000000\n0.000000\n0.033780\n0.041664\n0.059209\n0.000000\n0.041611\n0.000000\n0.061096\n0.0\n\n\n5\n0.106877\n0.000000\n0.112296\n0.000000\n0.032889\n1.000000\n0.000000\n0.187934\n0.000000\n0.083440\n0.083680\n0.101223\n0.032563\n0.000000\n0.000000\n0.042397\n0.0\n\n\n6\n0.000000\n0.041888\n0.060918\n0.000000\n0.000000\n0.000000\n1.000000\n0.036043\n0.049670\n0.060291\n0.000000\n0.171626\n0.000000\n0.000000\n0.048430\n0.000000\n0.0\n\n\n7\n0.234579\n0.035372\n0.276659\n0.000000\n0.000000\n0.187934\n0.036043\n1.000000\n0.210924\n0.000000\n0.027517\n0.017577\n0.068995\n0.000000\n0.089207\n0.055524\n0.0\n\n\n8\n0.000000\n0.048745\n0.200600\n0.058014\n0.000000\n0.000000\n0.049670\n0.210924\n1.000000\n0.000000\n0.000000\n0.099860\n0.000000\n0.000000\n0.222667\n0.000000\n0.0\n\n\n9\n0.034685\n0.000000\n0.096883\n0.000000\n0.033780\n0.083440\n0.060291\n0.000000\n0.000000\n1.000000\n0.000000\n0.091636\n0.000000\n0.000000\n0.000000\n0.043546\n0.0\n\n\n10\n0.116650\n0.000000\n0.032666\n0.029594\n0.041664\n0.083680\n0.000000\n0.027517\n0.000000\n0.000000\n1.000000\n0.074679\n0.000000\n0.099484\n0.000000\n0.000000\n0.0\n\n\n11\n0.067043\n0.000000\n0.041731\n0.075541\n0.059209\n0.101223\n0.171626\n0.017577\n0.099860\n0.091636\n0.074679\n1.000000\n0.033887\n0.000000\n0.000000\n0.024932\n0.0\n\n\n12\n0.077952\n0.058545\n0.033793\n0.031677\n0.000000\n0.032563\n0.000000\n0.068995\n0.000000\n0.000000\n0.000000\n0.033887\n1.000000\n0.000000\n0.054457\n0.000000\n0.0\n\n\n13\n0.042725\n0.000000\n0.000000\n0.044278\n0.041611\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.099484\n0.000000\n0.000000\n1.000000\n0.000000\n0.058398\n0.0\n\n\n14\n0.000000\n0.047528\n0.057351\n0.045509\n0.000000\n0.000000\n0.048430\n0.089207\n0.222667\n0.000000\n0.000000\n0.000000\n0.054457\n0.000000\n1.000000\n0.149209\n0.0\n\n\n15\n0.000000\n0.000000\n0.000000\n0.000000\n0.061096\n0.042397\n0.000000\n0.055524\n0.000000\n0.043546\n0.000000\n0.024932\n0.000000\n0.058398\n0.149209\n1.000000\n0.0\n\n\n16\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n1.0\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\nCosine Similarity Menggunakan Preprocessing\n\ncosine_preprocessing = cosine_similarity(tfidf_preprocessing, tfidf_preprocessing)\n\n\nsimilarity_preprocessing = pd.DataFrame(cosine_preprocessing, columns=range(len(kalimat)), index=range(len(kalimat)))\nsimilarity_preprocessing\n\n\n  \n    \n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n\n\n\n0\n1.000000\n0.000000\n0.152651\n0.060469\n0.047436\n0.131893\n0.000000\n0.295745\n0.000000\n0.043678\n0.112841\n0.104161\n0.092131\n0.000000\n0.000000\n0.000000\n0.0\n\n\n1\n0.000000\n1.000000\n0.000000\n0.000000\n0.105852\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.072819\n0.000000\n0.000000\n0.000000\n0.0\n\n\n2\n0.152651\n0.000000\n1.000000\n0.000000\n0.054547\n0.151663\n0.000000\n0.381721\n0.316919\n0.050225\n0.054610\n0.070955\n0.043710\n0.000000\n0.087843\n0.000000\n0.0\n\n\n3\n0.060469\n0.000000\n0.000000\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.126832\n0.000000\n0.068464\n0.111109\n0.000000\n0.000000\n0.000000\n0.000000\n0.0\n\n\n4\n0.047436\n0.105852\n0.054547\n0.000000\n1.000000\n0.047130\n0.000000\n0.000000\n0.000000\n0.049395\n0.000000\n0.034891\n0.000000\n0.000000\n0.000000\n0.083649\n0.0\n\n\n5\n0.131893\n0.000000\n0.151663\n0.000000\n0.047130\n1.000000\n0.000000\n0.156279\n0.000000\n0.043396\n0.047184\n0.061307\n0.037766\n0.000000\n0.000000\n0.000000\n0.0\n\n\n6\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.097365\n0.000000\n0.000000\n0.000000\n0.000000\n0.0\n\n\n7\n0.295745\n0.000000\n0.381721\n0.000000\n0.000000\n0.156279\n0.000000\n1.000000\n0.244551\n0.000000\n0.042140\n0.027376\n0.081749\n0.000000\n0.067784\n0.000000\n0.0\n\n\n8\n0.000000\n0.000000\n0.316919\n0.126832\n0.000000\n0.000000\n0.000000\n0.244551\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.106957\n0.000000\n0.0\n\n\n9\n0.043678\n0.000000\n0.050225\n0.000000\n0.049395\n0.043396\n0.000000\n0.000000\n0.000000\n1.000000\n0.000000\n0.098353\n0.000000\n0.000000\n0.000000\n0.000000\n0.0\n\n\n10\n0.112841\n0.000000\n0.054610\n0.068464\n0.000000\n0.047184\n0.000000\n0.042140\n0.000000\n0.000000\n1.000000\n0.082999\n0.000000\n0.000000\n0.000000\n0.000000\n0.0\n\n\n11\n0.104161\n0.000000\n0.070955\n0.111109\n0.034891\n0.061307\n0.097365\n0.027376\n0.000000\n0.098353\n0.082999\n1.000000\n0.049479\n0.000000\n0.000000\n0.000000\n0.0\n\n\n12\n0.092131\n0.072819\n0.043710\n0.000000\n0.000000\n0.037766\n0.000000\n0.081749\n0.000000\n0.000000\n0.000000\n0.049479\n1.000000\n0.000000\n0.000000\n0.000000\n0.0\n\n\n13\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n1.000000\n0.000000\n0.078835\n0.0\n\n\n14\n0.000000\n0.000000\n0.087843\n0.000000\n0.000000\n0.000000\n0.000000\n0.067784\n0.106957\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n1.000000\n0.195794\n0.0\n\n\n15\n0.000000\n0.000000\n0.000000\n0.000000\n0.083649\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.078835\n0.195794\n1.000000\n0.0\n\n\n16\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n1.0"
  },
  {
    "objectID": "news_summarization.html#graph",
    "href": "news_summarization.html#graph",
    "title": "4  Ringkasan Berita",
    "section": "9.2 Graph",
    "text": "9.2 Graph\nHasil dari nilai cosine simmilarity ini akan dapat digunakan untuk membentuk graph dengan menggunakan modul nx.graph. Graph ini akan menggambarkan ilustrasi dari kedekatan setiap kalimatnya dalam berita tersebut. Dalam proses penggambaran graph tersebut diperlukan ambang batas (treshold) yang digunakan untuk memberikan batasan agar keseluruhan kalimatnya tidak dihubungkan menggunakan garis (edge). Nilai ambang batas (treshold) yang digunakan adalah 0.1\nGraph Tanpa Preprocessing\n\nG = nx.DiGraph()\nfor i in range(len(cosine)):\n    G.add_node(i)\n\nfor i in range(len(cosine)):\n    for j in range(len(cosine)):\n        similarity = cosine[i][j]\n        if similarity &gt; 0.1 and i != j:\n            G.add_edge(i, j)\n\npos = nx.spring_layout(G)\nnx.draw_networkx_nodes(G, pos, node_size=500, node_color='b')\nnx.draw_networkx_edges(G, pos, edge_color='red', arrows=True)\nnx.draw_networkx_labels(G, pos)\n\nplt.show()\n\n\n\n\nGraph Menggunakan Preprocessing\n\nG_preprocessing = nx.DiGraph()\nfor i in range(len(cosine_preprocessing)):\n    G_preprocessing.add_node(i)\n\nfor i in range(len(cosine_preprocessing)):\n    for j in range(len(cosine_preprocessing)):\n        similarity_preprocessing = cosine_preprocessing[i][j]\n        if similarity_preprocessing &gt; 0.1 and i != j:\n            G_preprocessing.add_edge(i, j)\n\npos = nx.spring_layout(G)\nnx.draw_networkx_nodes(G, pos, node_size=500, node_color='b')\nnx.draw_networkx_edges(G, pos, edge_color='red', arrows=True)\nnx.draw_networkx_labels(G, pos)\n\nplt.show()"
  },
  {
    "objectID": "news_summarization.html#closeness-centrality",
    "href": "news_summarization.html#closeness-centrality",
    "title": "4  Ringkasan Berita",
    "section": "10.1 Closeness Centrality",
    "text": "10.1 Closeness Centrality\nCloseness similarity adalah ukuran sejauh mana nilai kedekatan antara pasangan node dalam suatu jaringan serupa. Dengan ini kita dapat mengukur kesamaan struktural antara node-node dalam graf berdasarkan nilai kedekatan mereka. Closeness similarity dirumuskan sebagai berikut.\n\\[CC(i) = \\frac{N-1}{\\sum_{j}d(i, j)} \\] \nKeterangan =  N = nomor dari masing-masing node  \\(d(i, j)\\) = d adalah panjang jalur terpendek antara node i dan j dalam jaringan\nCloseness Centrality Tanpa Preprocessing\n\ncloseness= nx.closeness_centrality(G)\n\nsorted_closeness = sorted(closeness.items(), key=lambda x: x[1], reverse=True)\nprint(\"Closeness Centrality:\")\nfor node, closeness in sorted_closeness:\n    print(f\"Node {node}: {closeness:.4f}\")\n\nCloseness Centrality:\nNode 2: 0.3164\nNode 7: 0.3164\nNode 5: 0.2978\nNode 0: 0.2812\nNode 8: 0.2664\nNode 11: 0.2201\nNode 14: 0.2025\nNode 10: 0.1947\nNode 6: 0.1633\nNode 15: 0.1534\nNode 1: 0.0625\nNode 4: 0.0625\nNode 3: 0.0000\nNode 9: 0.0000\nNode 12: 0.0000\nNode 13: 0.0000\nNode 16: 0.0000\n\n\n\nringkasan_closeness = \"\"\nprint(\"Tiga Node Tertinggi Closeness Centrality:\")\nfor node, closeness in sorted_closeness[:3]:\n    top_sentence = kalimat[node]\n    ringkasan_closeness += top_sentence + \" \"\n    print(f\"Node {node}: Closeness Centrality = {closeness:.4f}\")\n    print(f\"Kalimat: {top_sentence}\\n\")\n\nTiga Node Tertinggi Closeness Centrality:\nNode 2: Closeness Centrality = 0.3164\nKalimat: Pada saat bersamaan, Tito juga melantik Velix Vernando Wanggai sebagai Pj Gubernur Papua Pegunungan.\n\nNode 7: Closeness Centrality = 0.3164\nKalimat: Eks Stafsus SBY Velix Wanggai Jadi Pj Gubernur Papua Pegunungan Dia meminta Safrizal menangani permasalahan lingkungan di Bangka Belitung.\n\nNode 5: Closeness Centrality = 0.2978\nKalimat: Tito meminta dua pj gubernur menangani kemiskinan ekstrem, inflasi, stunting, infrastruktur, pendidikan, dan kesehatan.\n\n\n\nCloseness Centrality Menggunakan Preprocessing\n\ncloseness_preprocessing = nx.closeness_centrality(G_preprocessing)\n\nsorted_closeness_preprocessing = sorted(closeness_preprocessing.items(), key=lambda x: x[1], reverse=True)\nprint(\"Closeness Centrality:\")\nfor node, closeness in sorted_closeness_preprocessing:\n    print(f\"Node {node}: {closeness:.4f}\")\n\nCloseness Centrality:\nNode 2: 0.3375\nNode 7: 0.3375\nNode 8: 0.3375\nNode 0: 0.3164\nNode 3: 0.2664\nNode 5: 0.2664\nNode 11: 0.2664\nNode 14: 0.2411\nNode 10: 0.2109\nNode 15: 0.1746\nNode 1: 0.0625\nNode 4: 0.0625\nNode 6: 0.0000\nNode 9: 0.0000\nNode 12: 0.0000\nNode 13: 0.0000\nNode 16: 0.0000\n\n\n\nringkasan_closeness_preprocessing = \"\"\nprint(\"Tiga Node Tertinggi Closeness Centrality Menggunakan Preprocessing:\")\nfor node, closeness_preprocessing in sorted_closeness_preprocessing[:3]:\n    top_sentence = kalimat[node]\n    ringkasan_closeness_preprocessing += top_sentence + \" \"\n    print(f\"Node {node}: Closeness Centrality = {closeness_preprocessing:.4f}\")\n    print(f\"Kalimat: {top_sentence}\\n\")\n\nTiga Node Tertinggi Closeness Centrality Menggunakan Preprocessing:\nNode 2: Closeness Centrality = 0.3375\nKalimat: Pada saat bersamaan, Tito juga melantik Velix Vernando Wanggai sebagai Pj Gubernur Papua Pegunungan.\n\nNode 7: Closeness Centrality = 0.3375\nKalimat: Eks Stafsus SBY Velix Wanggai Jadi Pj Gubernur Papua Pegunungan Dia meminta Safrizal menangani permasalahan lingkungan di Bangka Belitung.\n\nNode 8: Closeness Centrality = 0.3375\nKalimat: Sementara untuk Velix, tugas keamanan di Papua Pegunungan menjadi prioritas."
  },
  {
    "objectID": "news_summarization.html#page-rank",
    "href": "news_summarization.html#page-rank",
    "title": "4  Ringkasan Berita",
    "section": "10.2 Page Rank",
    "text": "10.2 Page Rank\nDalam konteks ini, dokumen dianggap sebagai “halaman” yang terhubung oleh hubungan yang merefleksikan keterkaitan atau relevansinya. Dengan menerapkan konsep PageRank, dokumen yang dianggap lebih “penting” atau relevan dapat diberikan skor lebih tinggi. Penggunaan faktor damping, serupa dengan dalam algoritma PageRank, dapat membantu mengontrol sejauh mana pengaruh satu dokumen terhadap yang lain. Dengan memberikan skor pada dokumen berdasarkan hubungan mereka dalam jaringan informasi, kita dapat menghasilkan ringkasan yang mencerminkan tingkat relevansi dan pentingnya masing-masing dokumen dalam konteks keseluruhan.  \\[S(V_{i}) = (1-d)+d * \\sum\\frac{1}{Out(V_{j})}S(V_{j})\\] \nKeterangan =  d = faktor redaman, jika tidak ada sambungan keluar  in(Vi) = tautan masuk dari i, yang merupakan satu set  out(Vj) = tautan keluar dari j, yang merupakan satu set  |out(Vj)| = jumlah tautan keluar\nPage Rank Tanpa Preprocessing\n\npagerank = nx.pagerank(G)\n\nsorted_pagerank= sorted(pagerank.items(), key=lambda x: x[1], reverse=True)\nprint(\"Page Rank :\")\nfor node, pagerank in sorted_pagerank:\n    print(f\"Node {node}: {pagerank:.4f}\")\n\nPage Rank :\nNode 5: 0.1103\nNode 0: 0.1102\nNode 2: 0.1061\nNode 7: 0.1061\nNode 8: 0.0879\nNode 1: 0.0784\nNode 4: 0.0784\nNode 14: 0.0731\nNode 11: 0.0708\nNode 15: 0.0428\nNode 6: 0.0418\nNode 10: 0.0352\nNode 3: 0.0118\nNode 9: 0.0118\nNode 12: 0.0118\nNode 13: 0.0118\nNode 16: 0.0118\n\n\n\nringkasan_pagerank = \"\"\nprint(\"Tiga Node Tertinggi Page Rank :\")\nfor node, pagerank in sorted_pagerank[:3]:\n    top_sentence = kalimat[node]\n    ringkasan_pagerank += top_sentence + \" \"\n    print(f\"Node {node}: Page Rank = {pagerank:.4f}\")\n    print(f\"Kalimat: {top_sentence}\\n\")\n\nTiga Node Tertinggi Page Rank :\nNode 5: Page Rank = 0.1103\nKalimat: Tito meminta dua pj gubernur menangani kemiskinan ekstrem, inflasi, stunting, infrastruktur, pendidikan, dan kesehatan.\n\nNode 0: Page Rank = 0.1102\nKalimat: Menteri Dalam Negeri (Mendagri) Tito Karnavian menunjuk Safrizal ZA sebagai Penjabat (Pj) Gubernur Bangka Belitung.\n\nNode 2: Page Rank = 0.1061\nKalimat: Pada saat bersamaan, Tito juga melantik Velix Vernando Wanggai sebagai Pj Gubernur Papua Pegunungan.\n\n\n\nPage Rank Menggunakan Preprocessing\n\npagerank_preprocessing = nx.pagerank(G_preprocessing)\n\nsorted_pagerank_preprocessing= sorted(pagerank_preprocessing.items(), key=lambda x: x[1], reverse=True)\nprint(\"Page Rank :\")\nfor node, pagerank_preprocessing in sorted_pagerank_preprocessing:\n    print(f\"Node {node}: {pagerank_preprocessing:.4f}\")\n\nPage Rank :\nNode 0: 0.1303\nNode 8: 0.1102\nNode 2: 0.1003\nNode 7: 0.1003\nNode 1: 0.0784\nNode 4: 0.0784\nNode 5: 0.0766\nNode 14: 0.0707\nNode 3: 0.0605\nNode 11: 0.0596\nNode 15: 0.0418\nNode 10: 0.0339\nNode 6: 0.0118\nNode 9: 0.0118\nNode 12: 0.0118\nNode 13: 0.0118\nNode 16: 0.0118\n\n\n\nringkasan_pagerank_preprocessing = \"\"\nprint(\"Tiga Node Tertinggi Page Rank Menggunakan Preprocessing:\")\nfor node, pagerank_preprocessing in sorted_pagerank_preprocessing[:3]:\n    top_sentence = kalimat[node]\n    ringkasan_pagerank_preprocessing += top_sentence + \" \"\n    print(f\"Node {node}: Page Rank = {pagerank_preprocessing:.4f}\")\n    print(f\"Kalimat: {top_sentence}\\n\")\n\nTiga Node Tertinggi Page Rank Menggunakan Preprocessing:\nNode 0: Page Rank = 0.1303\nKalimat: Menteri Dalam Negeri (Mendagri) Tito Karnavian menunjuk Safrizal ZA sebagai Penjabat (Pj) Gubernur Bangka Belitung.\n\nNode 8: Page Rank = 0.1102\nKalimat: Sementara untuk Velix, tugas keamanan di Papua Pegunungan menjadi prioritas.\n\nNode 2: Page Rank = 0.1003\nKalimat: Pada saat bersamaan, Tito juga melantik Velix Vernando Wanggai sebagai Pj Gubernur Papua Pegunungan."
  },
  {
    "objectID": "news_summarization.html#eigen-vector",
    "href": "news_summarization.html#eigen-vector",
    "title": "4  Ringkasan Berita",
    "section": "10.3 Eigen Vector",
    "text": "10.3 Eigen Vector\nDalam ringkasan dokumen, eigenvector tidak digunakan secara langsung untuk menghitung ringkasan. Namun, Anda dapat memanfaatkan konsep pengukuran penting dari eigenvector untuk memberikan bobot atau skor pada elemen-elemen dalam dokumen yang mungkin memiliki kepentingan lebih besar dalam rangka membuat ringkasan. Perhitungan eigenvector yang didapatkan dari matriks korelasi untuk menentukan bobot relatif setiap dokumen atau kata. Berikut merupakan rumus untuk menghitung nilai eigenvector.  \\[det(λ.I-A)\\]\nKeterangan =  det(⋅) = Merupakan fungsi determinan, yang menghasilkan nilai determinan dari suatu matriks.  λ = Merupakan simbol yang mewakili eigenvalue yang sedang dicari.  I = Merupakan matriks identitas yang sesuai dengan dimensi matriks.  A = Merupakan matriks yang eigenvalues-nya ingin dicari.\nEigen Vector Tanpa Preprocessing\n\neigenvector = nx.eigenvector_centrality(G)\n\nsorted_eigenvector= sorted(eigenvector.items(), key=lambda x: x[1], reverse=True)\nprint(\"Eigen Vector :\")\nfor node, eigenvector in sorted_eigenvector:\n    print(f\"Node {node}: {eigenvector:.4f}\")\n\nEigen Vector :\nNode 2: 0.4823\nNode 7: 0.4823\nNode 5: 0.4453\nNode 0: 0.4426\nNode 8: 0.3053\nNode 11: 0.1398\nNode 10: 0.1274\nNode 14: 0.0958\nNode 6: 0.0402\nNode 15: 0.0276\nNode 1: 0.0000\nNode 4: 0.0000\nNode 3: 0.0000\nNode 9: 0.0000\nNode 12: 0.0000\nNode 13: 0.0000\nNode 16: 0.0000\n\n\n\nringkasan_eigenvector = \"\"\nprint(\"Tiga Node Tertinggi Eigen Vector:\")\nfor node, eigenvector in sorted_eigenvector[:3]:\n    top_sentence = kalimat[node]\n    ringkasan_eigenvector += top_sentence + \" \"\n    print(f\"Node {node}: Page Rank = {eigenvector:.4f}\")\n    print(f\"Kalimat: {top_sentence}\\n\")\n\nTiga Node Tertinggi Eigen Vector:\nNode 2: Page Rank = 0.4823\nKalimat: Pada saat bersamaan, Tito juga melantik Velix Vernando Wanggai sebagai Pj Gubernur Papua Pegunungan.\n\nNode 7: Page Rank = 0.4823\nKalimat: Eks Stafsus SBY Velix Wanggai Jadi Pj Gubernur Papua Pegunungan Dia meminta Safrizal menangani permasalahan lingkungan di Bangka Belitung.\n\nNode 5: Page Rank = 0.4453\nKalimat: Tito meminta dua pj gubernur menangani kemiskinan ekstrem, inflasi, stunting, infrastruktur, pendidikan, dan kesehatan.\n\n\n\n\neigenvector_preprocessing = nx.eigenvector_centrality(G_preprocessing)\n\nsorted_eigenvector_preprocessing= sorted(eigenvector_preprocessing.items(), key=lambda x: x[1], reverse=True)\nprint(\"Eigen Vector :\")\nfor node, eigenvector_preprocessing in sorted_eigenvector_preprocessing:\n    print(f\"Node {node}: {eigenvector_preprocessing:.4f}\")\n\nEigen Vector :\nNode 2: 0.4692\nNode 7: 0.4692\nNode 0: 0.4619\nNode 5: 0.3956\nNode 8: 0.3344\nNode 11: 0.1708\nNode 3: 0.1427\nNode 10: 0.1305\nNode 14: 0.1027\nNode 15: 0.0290\nNode 1: 0.0000\nNode 4: 0.0000\nNode 6: 0.0000\nNode 9: 0.0000\nNode 12: 0.0000\nNode 13: 0.0000\nNode 16: 0.0000\n\n\n\nringkasan_eigenvector_preprocessing = \"\"\nprint(\"Tiga Node Tertinggi Eigen Vector Menggunakan Preprocessing:\")\nfor node, eigenvector_preprocessing in sorted_eigenvector_preprocessing[:3]:\n    top_sentence = kalimat[node]\n    ringkasan_eigenvector_preprocessing += top_sentence + \" \"\n    print(f\"Node {node}: Page Rank = {eigenvector_preprocessing:.4f}\")\n    print(f\"Kalimat: {top_sentence}\\n\")\n\nTiga Node Tertinggi Eigen Vector Menggunakan Preprocessing:\nNode 2: Page Rank = 0.4692\nKalimat: Pada saat bersamaan, Tito juga melantik Velix Vernando Wanggai sebagai Pj Gubernur Papua Pegunungan.\n\nNode 7: Page Rank = 0.4692\nKalimat: Eks Stafsus SBY Velix Wanggai Jadi Pj Gubernur Papua Pegunungan Dia meminta Safrizal menangani permasalahan lingkungan di Bangka Belitung.\n\nNode 0: Page Rank = 0.4619\nKalimat: Menteri Dalam Negeri (Mendagri) Tito Karnavian menunjuk Safrizal ZA sebagai Penjabat (Pj) Gubernur Bangka Belitung."
  },
  {
    "objectID": "news_summarization.html#closeness-centrality-1",
    "href": "news_summarization.html#closeness-centrality-1",
    "title": "4  Ringkasan Berita",
    "section": "11.1 Closeness Centrality",
    "text": "11.1 Closeness Centrality\n\nrouge(referensi[0], ringkasan_closeness)\n\n[{'rouge-1': {'r': 0.3333333333333333, 'p': 0.5641025641025641, 'f': 0.41904761437823135}, 'rouge-2': {'r': 0.14864864864864866, 'p': 0.25, 'f': 0.1864406732892848}, 'rouge-l': {'r': 0.2878787878787879, 'p': 0.48717948717948717, 'f': 0.3619047572353742}}]\n\n\n\nrouge(referensi[0], ringkasan_closeness_preprocessing)\n\n[{'rouge-1': {'r': 0.22727272727272727, 'p': 0.42857142857142855, 'f': 0.2970296984413293}, 'rouge-2': {'r': 0.08108108108108109, 'p': 0.15384615384615385, 'f': 0.10619468574516426}, 'rouge-l': {'r': 0.18181818181818182, 'p': 0.34285714285714286, 'f': 0.23762375784726997}}]\n\n\nBerikut adalah hasil simpulan berdasarkan evaluasi ROUGE pada Closeness Centrality:\nBerdasarkan evaluasi ROUGE closeness centrality, ditemukan bahwa tanpa menggunakan preprocessing, sistem ringkasan cenderung mencapai hasil yang lebih baik. Secara khusus, pada metrik ROUGE-1, sistem tanpa preprocessing memiliki recall sekitar 0.33, precision sekitar 0.56, dan F1-Score sekitar 0.42. Sebaliknya, ketika menggunakan preprocessing, nilai recall turun menjadi sekitar 0.23, precision sekitar 0.43, dan F1-Score sekitar 0.30."
  },
  {
    "objectID": "news_summarization.html#page-rank-1",
    "href": "news_summarization.html#page-rank-1",
    "title": "4  Ringkasan Berita",
    "section": "11.2 Page Rank",
    "text": "11.2 Page Rank\n\nrouge(referensi[0], ringkasan_pagerank)\n\n[{'rouge-1': {'r': 0.4090909090909091, 'p': 0.675, 'f': 0.5094339575649698}, 'rouge-2': {'r': 0.24324324324324326, 'p': 0.4186046511627907, 'f': 0.3076923030433195}, 'rouge-l': {'r': 0.4090909090909091, 'p': 0.675, 'f': 0.5094339575649698}}]\n\n\n\nrouge(referensi[0], ringkasan_pagerank_preprocessing)\n\n[{'rouge-1': {'r': 0.30303030303030304, 'p': 0.5714285714285714, 'f': 0.39603959943142836}, 'rouge-2': {'r': 0.17567567567567569, 'p': 0.34210526315789475, 'f': 0.23214285265943885}, 'rouge-l': {'r': 0.30303030303030304, 'p': 0.5714285714285714, 'f': 0.39603959943142836}}]\n\n\nBerdasarkan hasil evaluasi ROUGE pada Page Rank untuk ringkasan dengan dan tanpa preprocessing menggunakan metode Page Rank, dapat disimpulkan bahwa tanpa preprocessing sistem mampu mencapai hasil yang lebih baik dalam sebagian besar metrik evaluasi. Pada metrik ROUGE-1, sistem tanpa preprocessing memiliki nilai recall sekitar 0.41, precision sekitar 0.675, dan F1-Score sekitar 0.51. Sementara itu, dengan preprocessing, nilai recall turun menjadi sekitar 0.30, precision sekitar 0.571, dan F1-Score sekitar 0.40"
  },
  {
    "objectID": "news_summarization.html#eigen-vector-1",
    "href": "news_summarization.html#eigen-vector-1",
    "title": "4  Ringkasan Berita",
    "section": "11.3 Eigen Vector",
    "text": "11.3 Eigen Vector\n\nrouge(referensi[0], ringkasan_eigenvector)\n\n[{'rouge-1': {'r': 0.3333333333333333, 'p': 0.5641025641025641, 'f': 0.41904761437823135}, 'rouge-2': {'r': 0.14864864864864866, 'p': 0.25, 'f': 0.1864406732892848}, 'rouge-l': {'r': 0.2878787878787879, 'p': 0.48717948717948717, 'f': 0.3619047572353742}}]\n\n\n\nrouge(referensi[0], ringkasan_eigenvector_preprocessing)\n\n[{'rouge-1': {'r': 0.30303030303030304, 'p': 0.5405405405405406, 'f': 0.3883495099594685}, 'rouge-2': {'r': 0.17567567567567569, 'p': 0.29545454545454547, 'f': 0.22033897837403055}, 'rouge-l': {'r': 0.30303030303030304, 'p': 0.5405405405405406, 'f': 0.3883495099594685}}]\n\n\nBerdasarkan hasil evaluasi ROUGE untuk ringkasan dengan dan tanpa preprocessing menggunakan metode eigenvector centrality, dapat ditarik beberapa kesimpulan. Tanpa preprocessing, sistem cenderung mencapai hasil yang sedikit lebih baik pada sebagian besar metrik evaluasi. Pada metrik ROUGE-1, sistem tanpa preprocessing memiliki nilai recall sekitar 0.33, precision sekitar 0.56, dan F1-Score sekitar 0.42. Sementara itu, dengan preprocessing, nilai recall dan F1-Score tetap stabil, sedangkan precision mengalami penurunan menjadi sekitar 0.54."
  }
]